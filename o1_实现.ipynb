{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "324850d5-de3f-4aaf-aff4-2e1978b91dcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T13:43:29.711359Z",
     "iopub.status.busy": "2025-01-06T13:43:29.710875Z",
     "iopub.status.idle": "2025-01-06T13:43:29.721663Z",
     "shell.execute_reply": "2025-01-06T13:43:29.719438Z",
     "shell.execute_reply.started": "2025-01-06T13:43:29.711319Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1c2f64-e4a9-459a-861c-ec8c7c8c062c",
   "metadata": {},
   "source": [
    "- thought tokens\n",
    "    - https://ollama.com/library/marco-o1/blobs/8c772364849c\n",
    "    - `当你回答问题时，你的思考应该在<Thought>内完成，<Output>内输出你的结果。\n",
    "<Thought>应该尽可能是英文，但是有2个特例，一个是对原文中的引用，另一个是是数学应该使用markdown格式，<Output>内的输出需要遵循用户输入的语言。`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282dc139-cdaa-4bc6-8dcc-458737a0712c",
   "metadata": {},
   "source": [
    "### StaR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d9b3ef-0705-4e3d-8126-05e99b95b8cc",
   "metadata": {},
   "source": [
    "- Self-taught Reasoner（Bootstrapping Reasoning With Reasoning）\n",
    "    - (question, rationale, answer)：自动化生成带 rationale 的更好的数据；\n",
    "        - 所谓的 learned CoT；\n",
    "    - rationale：解题步骤，可以理解为 CoT；\n",
    "        - intermediate reasoning steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f817b852-00db-4a77-addf-e678e9719eb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T13:43:42.015537Z",
     "iopub.status.busy": "2025-01-06T13:43:42.014964Z",
     "iopub.status.idle": "2025-01-06T13:43:42.034478Z",
     "shell.execute_reply": "2025-01-06T13:43:42.032220Z",
     "shell.execute_reply.started": "2025-01-06T13:43:42.015491Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://media.licdn.com/dms/image/v2/D4E22AQE0Wb4bvlwQWw/feedshare-shrink_2048_1536/feedshare-shrink_2048_1536/0/1729410843663?e=2147483647&v=beta&t=cAICS18uHKSPa8UcSsIHr4YUrAdgytw-6F6wUS8I3k8\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://media.licdn.com/dms/image/v2/D4E22AQE0Wb4bvlwQWw/feedshare-shrink_2048_1536/feedshare-shrink_2048_1536/0/1729410843663?e=2147483647&v=beta&t=cAICS18uHKSPa8UcSsIHr4YUrAdgytw-6F6wUS8I3k8', width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31f2c276-ec17-4589-9fab-bd22fa06ed18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T13:47:23.741950Z",
     "iopub.status.busy": "2025-01-06T13:47:23.741400Z",
     "iopub.status.idle": "2025-01-06T13:47:23.753189Z",
     "shell.execute_reply": "2025-01-06T13:47:23.751108Z",
     "shell.execute_reply.started": "2025-01-06T13:47:23.741906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.promptingguide.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcot.1933d9fe.png&w=1080&q=75\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://www.promptingguide.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcot.1933d9fe.png&w=1080&q=75', width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd40c7f-3e37-4bed-8ac4-d5811cab1fff",
   "metadata": {},
   "source": [
    "### Macro-O1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22169a3-3e13-440e-a12b-199732e01ca4",
   "metadata": {},
   "source": [
    "- https://arxiv.org/pdf/2411.14405\n",
    "    - https://github.com/AIDC-AI/Marco-o1\n",
    "    - 没有看到 mcts inference 的代码 release\n",
    "- Fine-Tuning with CoT Data: We develop Marco-o1-CoT by performing full-parameter fine-tuning\n",
    "on the base model using open-source CoT datasets combined with our synthetic data.\n",
    "- Solution Space Expansion via MCTS: We integrate LLMs with MCTS (Marco-o1-MCTS), using\n",
    "the model’s output confidence to guide the search and expand the solution space.\n",
    "- Reasoning Action Strategy: We implement novel reasoning action strategies and a reflection\n",
    "mechanism (Marco-o1-MCTS mini-step), including exploring different action granularities within\n",
    "the MCTS framework and prompting the model to self-reflect, thereby significantly enhancing the\n",
    "model’s ability to solve complex problems.\n",
    "- Application in Translation Tasks: We are the first to investigate LRM on Machine Translation tasks,\n",
    "exploring inference-time scaling laws in the multilingual and translation domain."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
