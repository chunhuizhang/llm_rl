{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1486818-09d3-467e-93c6-70f5ce024d2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T10:59:12.517861Z",
     "iopub.status.busy": "2024-12-21T10:59:12.517234Z",
     "iopub.status.idle": "2024-12-21T10:59:12.527193Z",
     "shell.execute_reply": "2024-12-21T10:59:12.525431Z",
     "shell.execute_reply.started": "2024-12-21T10:59:12.517812Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de160e7e-4f3b-4544-908f-7cffb890a687",
   "metadata": {},
   "source": [
    "### outcome vs. process supervision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055b7f6c-8830-41f4-a0d5-9f53a5bc7f4e",
   "metadata": {},
   "source": [
    "- 更容易得到（高质量）合成数据的领域\n",
    "    - coding & math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61757294-483e-4c79-9516-90c23148eacc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T10:59:24.398296Z",
     "iopub.status.busy": "2024-12-21T10:59:24.397730Z",
     "iopub.status.idle": "2024-12-21T10:59:24.415554Z",
     "shell.execute_reply": "2024-12-21T10:59:24.413454Z",
     "shell.execute_reply.started": "2024-12-21T10:59:24.398250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./imgs/outcome_supervised.png\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='./imgs/outcome_supervised.png', width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17ef8d03-a652-492f-b91a-cfb3a5c3169b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T10:59:37.925350Z",
     "iopub.status.busy": "2024-12-21T10:59:37.924756Z",
     "iopub.status.idle": "2024-12-21T10:59:37.937348Z",
     "shell.execute_reply": "2024-12-21T10:59:37.935266Z",
     "shell.execute_reply.started": "2024-12-21T10:59:37.925288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./imgs/process_supervised.png\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='./imgs/process_supervised.png', width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c993a4a-81d1-4e1f-96fc-48c65b313c96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T11:01:37.509346Z",
     "iopub.status.busy": "2024-12-21T11:01:37.508755Z",
     "iopub.status.idle": "2024-12-21T11:01:37.521392Z",
     "shell.execute_reply": "2024-12-21T11:01:37.519179Z",
     "shell.execute_reply.started": "2024-12-21T11:01:37.509285Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./imgs/combine.png\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='./imgs/combine.png', width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccd2feb-255d-4f59-817f-48e703bfb641",
   "metadata": {},
   "source": [
    "### self-play RL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885026d0-aac6-4515-b861-8deed4479c49",
   "metadata": {},
   "source": [
    "- RL in LLMs\n",
    "    - Context \\ Action \\ Reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d98b25-e7c4-4922-93f6-f04e69cfd1c9",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=EY9iHSe82Hc (Noam Brown)\n",
    "\n",
    "- games\n",
    "    - great verifier but a bad generator\n",
    "    - unlimited reward data\n",
    "- LLMs\n",
    "    - great generator but a bad verifier\n",
    "    - trillions of tokens of human text\n",
    "    - far less reward data\n",
    "- may change with time\n",
    "    - amount of reward data is increasing\n",
    "    - some domains are easier to score than others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cc26ae-95ad-49ca-a7f0-81b3695e9a91",
   "metadata": {},
   "source": [
    "### reward model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7566d42c-36b4-4f5b-bccf-f0738c66959f",
   "metadata": {},
   "source": [
    "- 经典的基于 preference + ranking loss （BT model） 训练的 reward model；\n",
    "- PRM（Progress Reward Model）\n",
    "    - 在数学等推理问题上，紧靠最后答案的正确性（outcome）来提供奖励信号（reward singal）是不足的；\n",
    "    - 一种可能得解决方案即是，引入对于每一步解题步骤的打分，来提供**细粒度的奖励信号**；"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
