{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27dfd576-6b9e-4033-aaf3-86e31375b011",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T16:16:41.249024Z",
     "iopub.status.busy": "2025-03-04T16:16:41.248763Z",
     "iopub.status.idle": "2025-03-04T16:16:41.253932Z",
     "shell.execute_reply": "2025-03-04T16:16:41.252834Z",
     "shell.execute_reply.started": "2025-03-04T16:16:41.249006Z"
    }
   },
   "outputs": [],
   "source": [
    "from vllm import SamplingParams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775e3b8a-053f-4351-877d-6c9abb6962fb",
   "metadata": {},
   "source": [
    "## vllm vs. sglang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb26885a-e5a5-4a85-bb8f-fb54c3bc508a",
   "metadata": {},
   "source": [
    "- vllm: A high-throughput and memory-efficient inference and serving engine for LLMs\n",
    "- sglang: SGLang is a fast serving framework for large language models and vision language models.\n",
    "- vllm/sglang is dynamic batch to inference,\n",
    "    - Validation datasets are sent to inference engines as a whole batch, which will schedule the memory themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d756015-7617-46bf-b8e2-169613a70b80",
   "metadata": {},
   "source": [
    "### dp vs. tp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eb690e-dcf6-40ab-bc03-51ba95f890d4",
   "metadata": {},
   "source": [
    "- 似乎有一个限制\n",
    "    - Total number of attention heads (xx) must be divisible by tensor parallel size (4)\n",
    "    - qwen2.5-7b: 28 attention heads\n",
    "        - 2卡，4卡，不能 8 卡；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b131125c-e1c0-46d2-bc5e-6c6d655e3be8",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cad087-97c8-4c38-9d83-8d28681b7976",
   "metadata": {},
   "source": [
    "## vllm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae5ec07-7de9-45b2-8881-e3844a61b9bb",
   "metadata": {},
   "source": [
    "- `LLM`\n",
    "    - `--max-model-len`: Model context length. If unspecified, will be automatically derived from the model config.\n",
    "        - `max_seq_len`\n",
    "        - `Qwen/Qwen2.5-7B-Instruct-1M` (config.json, `max_position_embeddings: 1010000`)\n",
    "    - `max_num_seqs`=256,  # 控制批处理中的最大序列数（batch size）\n",
    "    - `max_num_batched_tokens`=4096,  # 控制批处理中的最大token数\n",
    "- `SamplingParams`\n",
    "    - `max_tokens`: Maximum number of tokens to generate per output sequence.\n",
    "    - `stop`, ` stop_token_ids`\n",
    "        - `stop=stop_condition`\n",
    "     \n",
    "```python\n",
    "llm = LLM('Qwen/Qwen2.5-7B-Instruct')\n",
    "llm.llm_engine.scheduler_config.max_model_len # 32768\n",
    "llm.llm_engine.scheduler_config.max_num_seqs # 256\n",
    "llm.llm_engine.scheduler_config.max_num_batched_tokens # 32768\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefb60e3-f895-4e60-bfb6-d1358ea2af82",
   "metadata": {},
   "source": [
    "### sglang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419262b2-60e9-4e44-86bc-fe836fb5d910",
   "metadata": {},
   "source": [
    "- https://docs.sglang.ai/backend/server_arguments.html\n",
    "- https://docs.sglang.ai/backend/offline_engine_api.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
