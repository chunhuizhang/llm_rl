{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd728cee-b4c8-4279-832a-da72bd1d5327",
   "metadata": {},
   "source": [
    "- https://blog.vllm.ai/2023/06/20/vllm.html\n",
    "- https://docs.vllm.ai/en/latest/design/kernel/paged_attention.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e0129b-05d6-4dcc-89e7-9c2032245271",
   "metadata": {},
   "source": [
    "### parallel sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844f020b-3965-4ba1-84ec-435dea0fcb58",
   "metadata": {},
   "source": [
    "- 场景，multiple sampling 、 reject sampling\n",
    "- CoW mechanism（写时复制）\n",
    "    - To ensure safe sharing, PagedAttention keeps track of the **reference counts**(引用计数) of the physical blocks and implements the Copy-on-Write mechanism.\n",
    "        - 当多个不同的请求（或序列）需要访问完全相同的数据时（例如，它们有共同的提示前缀），PagedAttention 不会为每个请求都复制一份物理内存块。相反，它会让这些请求的逻辑块都指向同一个物理内存块。\n",
    "        - 为了知道这个物理块被多少个逻辑块共享着，系统会维护一个引用计数。每当有一个新的逻辑块指向这个物理块时，它的引用计数就加 1。\n",
    "        - ref cont > 1 时，如果要修改，会触发 CoW；\n",
    "    - 想象一下，你有一份很重要的参考资料（比如一本厚书），你的几个朋友都想看。\n",
    "        - 直接复制（效率低）： 如果你为每个朋友都复印一份完整的书，会非常耗费时间和纸张（资源）。尤其是如果他们大部分时间只是阅读，并不在上面写字。\n",
    "        - 共享（初始状态）： 你可以先把你的原版书放在桌子上，告诉所有朋友：“大家先看这一本，只要不往上面写字就行。” 这样，大家都共享同一份资源，非常高效。\n",
    "        - 写时复制（COW）： 当某个朋友（比如小明）忍不住想在书上做笔记或划重点时（也就是要“写入”），你不能让他直接在原版上写，不然会影响其他人。这时，你赶紧拿出复印机，只在小明要写的那一刻，帮他复印一份他专属的书。然后，小明就可以在他自己的复印本上随意写画了。其他朋友仍然看原来的那本，不受影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36681fbc-f334-48ec-bbe8-09b7aba3aa5d",
   "metadata": {},
   "source": [
    "### APC（Automatic Prefix Caching）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a23fef-9f98-44cc-98be-6afe30e178fa",
   "metadata": {},
   "source": [
    "- https://docs.vllm.ai/en/stable/features/automatic_prefix_caching.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdbe3084-08fa-41af-aa5e-26c142cfc01d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T12:07:24.722579Z",
     "iopub.status.busy": "2025-04-18T12:07:24.722279Z",
     "iopub.status.idle": "2025-04-18T12:07:24.730284Z",
     "shell.execute_reply": "2025-04-18T12:07:24.728395Z",
     "shell.execute_reply.started": "2025-04-18T12:07:24.722553Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c2e151b-7a42-4424-b062-13957d7778c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T12:03:05.514957Z",
     "iopub.status.busy": "2025-04-18T12:03:05.514572Z",
     "iopub.status.idle": "2025-04-18T12:03:05.526048Z",
     "shell.execute_reply": "2025-04-18T12:03:05.523725Z",
     "shell.execute_reply.started": "2025-04-18T12:03:05.514929Z"
    }
   },
   "outputs": [],
   "source": [
    "LONG_PROMPT = \"You are a helpful assistant in recognizes the content of tables in markdown format. Here is a table as follows.\\n# Table\\n\" + \"\"\"\n",
    "| ID  | Name          | Age | Occupation    | Country       | Email                  | Phone Number   | Address                       |\n",
    "|-----|---------------|-----|---------------|---------------|------------------------|----------------|------------------------------|\n",
    "| 1   | John Doe      | 29  | Engineer      | USA           | john.doe@example.com   | 555-1234       | 123 Elm St, Springfield, IL  |\n",
    "| 2   | Jane Smith    | 34  | Doctor        | Canada        | jane.smith@example.com | 555-5678       | 456 Oak St, Toronto, ON      |\n",
    "| 3   | Alice Johnson | 27  | Teacher       | UK            | alice.j@example.com    | 555-8765       | 789 Pine St, London, UK      |\n",
    "| 4   | Bob Brown     | 45  | Artist        | Australia     | bob.b@example.com      | 555-4321       | 321 Maple St, Sydney, NSW    |\n",
    "| 5   | Carol White   | 31  | Scientist     | New Zealand   | carol.w@example.com    | 555-6789       | 654 Birch St, Wellington, NZ |\n",
    "| 6   | Dave Green    | 28  | Lawyer        | Ireland       | dave.g@example.com     | 555-3456       | 987 Cedar St, Dublin, IE     |\n",
    "| 7   | Emma Black    | 40  | Musician      | USA           | emma.b@example.com     | 555-1111       | 246 Ash St, New York, NY     |\n",
    "| 8   | Frank Blue    | 37  | Chef          | Canada        | frank.b@example.com    | 555-2222       | 135 Spruce St, Vancouver, BC |\n",
    "| 9   | Grace Yellow  | 50  | Engineer      | UK            | grace.y@example.com    | 555-3333       | 864 Fir St, Manchester, UK   |\n",
    "| 10  | Henry Violet  | 32  | Artist        | Australia     | henry.v@example.com    | 555-4444       | 753 Willow St, Melbourne, VIC|\n",
    "| 11  | Irene Orange  | 26  | Scientist     | New Zealand   | irene.o@example.com    | 555-5555       | 912 Poplar St, Auckland, NZ  |\n",
    "| 12  | Jack Indigo   | 38  | Teacher       | Ireland       | jack.i@example.com     | 555-6666       | 159 Elm St, Cork, IE         |\n",
    "| 13  | Karen Red     | 41  | Lawyer        | USA           | karen.r@example.com    | 555-7777       | 357 Cedar St, Boston, MA     |\n",
    "| 14  | Leo Brown     | 30  | Chef          | Canada        | leo.b@example.com      | 555-8888       | 246 Oak St, Calgary, AB      |\n",
    "| 15  | Mia Green     | 33  | Musician      | UK            | mia.g@example.com      | 555-9999       | 975 Pine St, Edinburgh, UK   |\n",
    "| 16  | Noah Yellow   | 29  | Doctor        | Australia     | noah.y@example.com     | 555-0000       | 864 Birch St, Brisbane, QLD  |\n",
    "| 17  | Olivia Blue   | 35  | Engineer      | New Zealand   | olivia.b@example.com   | 555-1212       | 753 Maple St, Hamilton, NZ   |\n",
    "| 18  | Peter Black   | 42  | Artist        | Ireland       | peter.b@example.com    | 555-3434       | 912 Fir St, Limerick, IE     |\n",
    "| 19  | Quinn White   | 28  | Scientist     | USA           | quinn.w@example.com    | 555-5656       | 159 Willow St, Seattle, WA   |\n",
    "| 20  | Rachel Red    | 31  | Teacher       | Canada        | rachel.r@example.com   | 555-7878       | 357 Poplar St, Ottawa, ON    |\n",
    "| 21  | Steve Green   | 44  | Lawyer        | UK            | steve.g@example.com    | 555-9090       | 753 Elm St, Birmingham, UK   |\n",
    "| 22  | Tina Blue     | 36  | Musician      | Australia     | tina.b@example.com     | 555-1213       | 864 Cedar St, Perth, WA      |\n",
    "| 23  | Umar Black    | 39  | Chef          | New Zealand   | umar.b@example.com     | 555-3435       | 975 Spruce St, Christchurch, NZ|\n",
    "| 24  | Victor Yellow | 43  | Engineer      | Ireland       | victor.y@example.com   | 555-5657       | 246 Willow St, Galway, IE    |\n",
    "| 25  | Wendy Orange  | 27  | Artist        | USA           | wendy.o@example.com    | 555-7879       | 135 Elm St, Denver, CO       |\n",
    "| 26  | Xavier Green  | 34  | Scientist     | Canada        | xavier.g@example.com   | 555-9091       | 357 Oak St, Montreal, QC     |\n",
    "| 27  | Yara Red      | 41  | Teacher       | UK            | yara.r@example.com     | 555-1214       | 975 Pine St, Leeds, UK       |\n",
    "| 28  | Zack Blue     | 30  | Lawyer        | Australia     | zack.b@example.com     | 555-3436       | 135 Birch St, Adelaide, SA   |\n",
    "| 29  | Amy White     | 33  | Musician      | New Zealand   | amy.w@example.com      | 555-5658       | 159 Maple St, Wellington, NZ |\n",
    "| 30  | Ben Black     | 38  | Chef          | Ireland       | ben.b@example.com      | 555-7870       | 246 Fir St, Waterford, IE    |\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc6bd9a3-1662-46ae-a7c4-6b8df2452c7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T12:03:44.564489Z",
     "iopub.status.busy": "2025-04-18T12:03:44.563717Z",
     "iopub.status.idle": "2025-04-18T12:03:44.575513Z",
     "shell.execute_reply": "2025-04-18T12:03:44.573128Z",
     "shell.execute_reply.started": "2025-04-18T12:03:44.564423Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_generation_time(llm, sampling_params, prompts):\n",
    "    # time the generation\n",
    "    start_time = time.time()\n",
    "    output = llm.generate(prompts, sampling_params=sampling_params)\n",
    "    end_time = time.time()\n",
    "    # print the output and generation time\n",
    "    print(f\"Output: {output[0].outputs[0].text}\")\n",
    "    print(f\"Generation time: {end_time - start_time} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fed9f15-77cb-4d5f-bb8c-f495a7ef5671",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T12:04:12.772101Z",
     "iopub.status.busy": "2025-04-18T12:04:12.771354Z",
     "iopub.status.idle": "2025-04-18T12:05:49.756811Z",
     "shell.execute_reply": "2025-04-18T12:05:49.754468Z",
     "shell.execute_reply.started": "2025-04-18T12:04:12.772035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-18 20:04:23 [config.py:585] This model supports multiple tasks: {'score', 'reward', 'generate', 'embed', 'classify'}. Defaulting to 'generate'.\n",
      "INFO 04-18 20:04:23 [config.py:1697] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 04-18 20:04:25 [core.py:54] Initializing a V1 LLM engine (v0.8.2) with config: model='Qwen/Qwen2.5-3B-Instruct', speculative_config=None, tokenizer='Qwen/Qwen2.5-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=Qwen/Qwen2.5-3B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 04-18 20:04:26 [utils.py:2321] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x72719bcb5420>\n",
      "INFO 04-18 20:04:26 [parallel_state.py:954] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 04-18 20:04:26 [cuda.py:220] Using Flash Attention backend on V1 engine.\n",
      "INFO 04-18 20:04:26 [gpu_model_runner.py:1174] Starting to load model Qwen/Qwen2.5-3B-Instruct...\n",
      "WARNING 04-18 20:04:26 [topk_topp_sampler.py:63] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 04-18 20:04:28 [weight_utils.py:265] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.38it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.82it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.74it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-18 20:04:29 [loader.py:447] Loading weights took 1.19 seconds\n",
      "INFO 04-18 20:04:30 [gpu_model_runner.py:1186] Model loading took 5.7916 GB and 3.318596 seconds\n",
      "INFO 04-18 20:04:40 [backends.py:415] Using cache directory: /home/whaow/.cache/vllm/torch_compile_cache/14f004164d/rank_0_0 for vLLM's torch.compile\n",
      "INFO 04-18 20:04:40 [backends.py:425] Dynamo bytecode transform time: 10.76 s\n",
      "INFO 04-18 20:04:44 [backends.py:132] Cache the graph of shape None for later use\n",
      "INFO 04-18 20:05:13 [backends.py:144] Compiling a graph for general shape takes 31.70 s\n",
      "INFO 04-18 20:05:25 [monitor.py:33] torch.compile takes 42.47 s in total\n",
      "INFO 04-18 20:05:26 [kv_cache_utils.py:566] GPU KV cache size: 273,184 tokens\n",
      "INFO 04-18 20:05:26 [kv_cache_utils.py:569] Maximum concurrency for 32,768 tokens per request: 8.34x\n",
      "INFO 04-18 20:05:49 [gpu_model_runner.py:1534] Graph capturing finished in 23 secs, took 1.82 GiB\n",
      "INFO 04-18 20:05:49 [core.py:151] init engine (profile, create kv cache, warmup model) took 79.54 seconds\n"
     ]
    }
   ],
   "source": [
    "# set enable_prefix_caching=True to enable APC\n",
    "llm = LLM(\n",
    "    model='Qwen/Qwen2.5-3B-Instruct',\n",
    "    enable_prefix_caching=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66a87059-dae5-4859-89a7-ff3d896ed098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T12:06:43.200224Z",
     "iopub.status.busy": "2025-04-18T12:06:43.199767Z",
     "iopub.status.idle": "2025-04-18T12:06:43.209724Z",
     "shell.execute_reply": "2025-04-18T12:06:43.207606Z",
     "shell.execute_reply.started": "2025-04-18T12:06:43.200168Z"
    }
   },
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(temperature=0, max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf841b87-278d-4bb1-90b6-6f88de259f40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T12:07:27.640185Z",
     "iopub.status.busy": "2025-04-18T12:07:27.639455Z",
     "iopub.status.idle": "2025-04-18T12:07:29.212001Z",
     "shell.execute_reply": "2025-04-18T12:07:29.210248Z",
     "shell.execute_reply.started": "2025-04-18T12:07:27.640120Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen2.5-3B-Instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "356dffdd-0fa9-4f93-919e-1fb8ff482ea7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T12:09:27.240404Z",
     "iopub.status.busy": "2025-04-18T12:09:27.239633Z",
     "iopub.status.idle": "2025-04-18T12:09:27.293501Z",
     "shell.execute_reply": "2025-04-18T12:09:27.290970Z",
     "shell.execute_reply.started": "2025-04-18T12:09:27.240334Z"
    }
   },
   "outputs": [],
   "source": [
    "msg = [{'role': 'system', 'content': LONG_PROMPT}, \n",
    "      {'role': 'user', 'content': 'What is the age of John Doe?'}]\n",
    "prompt = tokenizer.apply_chat_template(msg, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb664554-93cc-4da7-b2d0-21ad67c93207",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T12:09:42.509390Z",
     "iopub.status.busy": "2025-04-18T12:09:42.508626Z",
     "iopub.status.idle": "2025-04-18T12:09:42.778918Z",
     "shell.execute_reply": "2025-04-18T12:09:42.776434Z",
     "shell.execute_reply.started": "2025-04-18T12:09:42.509322Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s, est. speed input: 7072.37 toks/s, output: 65.67 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: According to the table, John Doe is 29 years old.\n",
      "Generation time: 0.2613101005554199 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "get_generation_time(\n",
    "    llm,\n",
    "    sampling_params,\n",
    "    prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7d7752c-85ab-4794-8486-cd7b8fce8a58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T12:10:43.279460Z",
     "iopub.status.busy": "2025-04-18T12:10:43.278689Z",
     "iopub.status.idle": "2025-04-18T12:10:43.291990Z",
     "shell.execute_reply": "2025-04-18T12:10:43.289497Z",
     "shell.execute_reply.started": "2025-04-18T12:10:43.279384Z"
    }
   },
   "outputs": [],
   "source": [
    "msg = [{'role': 'system', 'content': LONG_PROMPT}, \n",
    "      {'role': 'user', 'content': 'What is the age of Zack Blue?'}]\n",
    "prompt = tokenizer.apply_chat_template(msg, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5490bd45-6af1-4b9a-85ce-6bb64e94b2ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T12:11:01.025855Z",
     "iopub.status.busy": "2025-04-18T12:11:01.025086Z",
     "iopub.status.idle": "2025-04-18T12:11:01.207927Z",
     "shell.execute_reply": "2025-04-18T12:11:01.205391Z",
     "shell.execute_reply.started": "2025-04-18T12:11:01.025788Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, est. speed input: 10622.64 toks/s, output: 98.62 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: According to the table, Zack Blue is 30 years old.\n",
      "Generation time: 0.1722562313079834 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "get_generation_time(\n",
    "    llm,\n",
    "    sampling_params,\n",
    "    prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c57389-5c83-484f-86b8-82fde481044f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "casual",
   "language": "python",
   "name": "casual"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
