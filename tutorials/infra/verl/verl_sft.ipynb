{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a735332e-db88-4141-aab1-7065da210ad4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T14:48:01.412588Z",
     "iopub.status.busy": "2025-05-08T14:48:01.411964Z",
     "iopub.status.idle": "2025-05-08T14:48:01.570165Z",
     "shell.execute_reply": "2025-05-08T14:48:01.569479Z",
     "shell.execute_reply.started": "2025-05-08T14:48:01.412525Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4259e6-6a1d-403a-847f-0078d94a9b22",
   "metadata": {},
   "source": [
    "### training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6602101-a8b8-429e-ac7a-4c8fccf6a7c9",
   "metadata": {},
   "source": [
    "- loss_mask\n",
    "    - 指示哪些token的预测应该被计入损失（例如，在多轮对话中，可能只计算回答部分的损失，而不计算提示部分的损失）。它通常排除了最后一个token，因为最后一个token没有下一个token可供预测。\n",
    "- logits\n",
    "    - shape: `[batch_size, seq_len, vocab_size]`\n",
    "- 对齐 logits 与 labels\n",
    "    - `labels` (目标) 通常是 `input_ids` 向左移动一位得到 (`input_ids[:, 1:]`)。\n",
    "    - `shift_logits` 是 logits 去掉最后一个时间步的预测 (`logits[..., :-1, :]`)，以与 labels 对齐。\n",
    "- 逐 token 计算 loss\n",
    "    - `nn.CrossEntropyLoss(reduction=\"none\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e68778-f281-4626-b340-2f2d59147bee",
   "metadata": {},
   "source": [
    "### traing loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b5ae36-20ec-4a2c-a72c-87807db16620",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{CE}=-\\log(P_{\\text{true\\_token}})\n",
    "$$\n",
    "\n",
    "- 假如训练到 0.3 的 loss 水平\n",
    "    - $P_{\\text{true\\_token}}=\\exp(-0.3)=0.7408$\n",
    "- 考虑到 qwen vocab size 152064 的水平\n",
    "    - 瞎猜 $\\text{CE}_{\\text{rand}}=-\\log(\\frac1{152064})=11.93$\n",
    "- 从 PPL（perplexity）的角度\n",
    "    - $PPL=\\exp(\\text{CE})$\n",
    "        - CEL = 0.3 => PPL = 1.35 (能将下一个最可能的词的范围缩小到好像平均只有 1 到 2 个（1.3634）选项一样。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8221d090-8d98-45d0-a166-3f381a0a847a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T14:51:59.764370Z",
     "iopub.status.busy": "2025-05-08T14:51:59.763740Z",
     "iopub.status.idle": "2025-05-08T14:51:59.778666Z",
     "shell.execute_reply": "2025-05-08T14:51:59.776505Z",
     "shell.execute_reply.started": "2025-05-08T14:51:59.764291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7408182206817179,\n",
       " 11.932056763842207,\n",
       " 1.3498588075760032,\n",
       " 151751.56167916086)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-0.3), np.log(152064), np.exp(0.3), np.exp(11.93)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22796e6-82bb-4d4c-8261-0ffb9fa8f847",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "casual",
   "language": "python",
   "name": "casual"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
