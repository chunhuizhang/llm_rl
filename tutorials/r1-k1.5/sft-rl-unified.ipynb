{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43cb0fc2-63e2-4da8-85a4-fbbefa366cbe",
   "metadata": {},
   "source": [
    "- 都是 policy gradient，都是用 gradient descent 来优化\n",
    "    - 使得有利的“动作”概率上升，不利的概率下降：\n",
    "    - 交叉熵损失通过梯度下降机制，增大正确类别的概率，同时减少错误类别的概率，符合分类任务的优化目标。\n",
    "    - 交叉熵损失（监督学习）：\n",
    "        - 目标：使模型预测的概率分布逼近真实标签的 one-hot 分布。\n",
    "        - 更新逻辑：正确类别的概率上升，错误类别的概率下降。\n",
    "    - 策略梯度（强化学习）：\n",
    "        - 目标：最大化未来累积奖励的期望。\n",
    "        - 更新逻辑：若某个动作带来高奖励，则提高其概率；反之则降低。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823d3592-cefa-42f7-a337-9909e86318e1",
   "metadata": {},
   "source": [
    "### 监督学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94afde57-4512-4231-9fd7-821cc4017174",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T03:40:03.569932Z",
     "iopub.status.busy": "2025-02-15T03:40:03.569541Z",
     "iopub.status.idle": "2025-02-15T03:40:05.331325Z",
     "shell.execute_reply": "2025-02-15T03:40:05.329362Z",
     "shell.execute_reply.started": "2025-02-15T03:40:03.569901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始梯度: tensor([-0.8000,  0.5000,  0.3000])\n",
      "更新后的概率分布: [0.2203 0.4836 0.296 ]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 初始化模型参数（logits），使得 softmax 后得到初始概率 [0.2, 0.5, 0.3]\n",
    "logits = torch.log(torch.tensor([0.2, 0.5, 0.3]))  # 将概率转换为 logits\n",
    "logits.requires_grad_(True)  # 启用梯度追踪\n",
    "\n",
    "target = torch.tensor(0)  # 真实标签是 \"北京\"（索引0）\n",
    "\n",
    "# 计算交叉熵损失（自动包含 softmax）\n",
    "loss = F.cross_entropy(logits.unsqueeze(0), target.unsqueeze(0))  # 添加 batch 维度\n",
    "\n",
    "# 反向传播计算梯度\n",
    "loss.backward()\n",
    "\n",
    "print(\"原始梯度:\", logits.grad)  # 梯度公式：∂loss/∂logits = (softmax_output - one_hot_target)\n",
    "\n",
    "# 梯度下降更新（学习率设为 0.1）\n",
    "with torch.no_grad():\n",
    "    logits -= 0.1 * logits.grad  # 执行参数更新\n",
    "\n",
    "# 计算新的概率分布\n",
    "new_probs = F.softmax(logits, dim=0)\n",
    "\n",
    "print(\"更新后的概率分布:\", new_probs.detach().numpy().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "467d8f72-c714-41e6-8947-ce3b8b1d5e75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T03:40:14.684507Z",
     "iopub.status.busy": "2025-02-15T03:40:14.684013Z",
     "iopub.status.idle": "2025-02-15T03:40:14.703479Z",
     "shell.execute_reply": "2025-02-15T03:40:14.701353Z",
     "shell.execute_reply.started": "2025-02-15T03:40:14.684468Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8000,  0.5000,  0.3000])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d1c9fb-d31b-4e4f-85e0-6fcbac9e5dd2",
   "metadata": {},
   "source": [
    "## RL policy gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e8ac42d-340d-40d0-9cfe-637d35f48311",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T04:06:20.088587Z",
     "iopub.status.busy": "2025-02-15T04:06:20.087970Z",
     "iopub.status.idle": "2025-02-15T04:06:20.102732Z",
     "shell.execute_reply": "2025-02-15T04:06:20.100759Z",
     "shell.execute_reply.started": "2025-02-15T04:06:20.088540Z"
    }
   },
   "outputs": [],
   "source": [
    "# 初始化策略网络参数\n",
    "logits = torch.tensor([0.2, 0.5, 0.3]).log().requires_grad_(True)\n",
    "action_probs = F.softmax(logits, dim=0)\n",
    "\n",
    "# 采样动作并获取回报（假设动作 0 的回报 G=1.0）\n",
    "sampled_action = 0\n",
    "reward = 1.0\n",
    "\n",
    "# 计算策略梯度\n",
    "obj = torch.log(action_probs[sampled_action]) * reward\n",
    "obj.backward()\n",
    "\n",
    "# 更新 logits（高回报动作的概率上升）\n",
    "with torch.no_grad():\n",
    "    logits += 0.1 * logits.grad\n",
    "\n",
    "# 新的概率分布\n",
    "new_probs = F.softmax(logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "308e858e-ac51-4280-ac7a-2915a6b47c02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T04:06:21.953687Z",
     "iopub.status.busy": "2025-02-15T04:06:21.953075Z",
     "iopub.status.idle": "2025-02-15T04:06:21.966554Z",
     "shell.execute_reply": "2025-02-15T04:06:21.964703Z",
     "shell.execute_reply.started": "2025-02-15T04:06:21.953641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2203, 0.4836, 0.2960], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ab5113-d69e-4519-9eae-25e612fb1059",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
