{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0505422-059f-4fd3-a24f-81756f62db94",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{GRPO:} \\quad\n",
    "\\frac{1}{G} \\sum_{i=1}^{G} \\textcolor{red}{\\frac{1}{|\\mathbf{o}_i|}} \\sum_{t=1}^{|\\mathbf{o}_i|} \n",
    "\\left\\{ \n",
    "    \\min \\left[\n",
    "        \\frac{\\pi_\\theta(o_{i,t} \\mid \\mathbf{q}, \\mathbf{o}_{i,<t})}{\\pi_{\\theta_{\\text{old}}}(o_{i,t} \\mid \\mathbf{q}, \\mathbf{o}_{i,<t})} \\hat{A}_{i,t},\n",
    "        \\mathrm{clip} \\left( \n",
    "            \\frac{\\pi_\\theta(o_{i,t} \\mid \\mathbf{q}, \\mathbf{o}_{i,<t})}{\\pi_{\\theta_{\\text{old}}}(o_{i,t} \\mid \\mathbf{q}, \\mathbf{o}_{i,<t})},\n",
    "            1 - \\epsilon, 1 + \\epsilon\n",
    "        \\right) \\hat{A}_{i,t}\n",
    "    \\right]\n",
    "\\right\\}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{where} \\quad\n",
    "\\hat{A}_{i,t} = \n",
    "\\frac{\n",
    "R(\\mathbf{q}, \\mathbf{o}_i) - \\mathrm{mean}(\\{ R(\\mathbf{q}, \\mathbf{o}_1), \\ldots, R(\\mathbf{q}, \\mathbf{o}_G) \\})\n",
    "}{\n",
    "\\textcolor{red}{\n",
    "\\mathrm{std}(\\{ R(\\mathbf{q}, \\mathbf{o}_1), \\ldots, R(\\mathbf{q}, \\mathbf{o}_G) \\})\n",
    "}\n",
    "}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "$$\n",
    "\\textbf{Dr. GRPO:} \\quad \\text{GRPO Done Right (without bias)} \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{1}{G} \\sum_{i=1}^{G} \\sum_{t=1}^{|\\mathbf{o}_i|} \n",
    "\\left\\{ \n",
    "    \\min \\left[\n",
    "        \\frac{\\pi_\\theta(o_{i,t} \\mid \\mathbf{q}, \\mathbf{o}_{i,<t})}{\\pi_{\\theta_{\\text{old}}}(o_{i,t} \\mid \\mathbf{q}, \\mathbf{o}_{i,<t})} \\hat{A}_{i,t},\n",
    "        \\mathrm{clip} \\left( \n",
    "            \\frac{\\pi_\\theta(o_{i,t} \\mid \\mathbf{q}, \\mathbf{o}_{i,<t})}{\\pi_{\\theta_{\\text{old}}}(o_{i,t} \\mid \\mathbf{q}, \\mathbf{o}_{i,<t})},\n",
    "            1 - \\epsilon, 1 + \\epsilon\n",
    "        \\right) \\hat{A}_{i,t}\n",
    "    \\right]\n",
    "\\right\\}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{where} \\quad\n",
    "\\hat{A}_{i,t} = R(\\mathbf{q}, \\mathbf{o}_i) - \\mathrm{mean}(\\{ R(\\mathbf{q}, \\mathbf{o}_1), \\ldots, R(\\mathbf{q}, \\mathbf{o}_G) \\})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f1045b-f006-485d-abb6-01a7da3eebc0",
   "metadata": {},
   "source": [
    "- Dr. GRPO\n",
    "    - https://arxiv.org/pdf/2503.20783\n",
    "    - 移除了内部的平均，计算 advantage 不需要除以 std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d665aa-fa68-47ee-8202-fda045f14cad",
   "metadata": {},
   "source": [
    "### basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b20ab9-141b-4cbc-a9ee-0c691a978c0d",
   "metadata": {},
   "source": [
    "- steps\n",
    "    - effective_batch_size: per_device_train_batch_size * num_processes * gradient_accumulation_steps\n",
    "        - 8 * 2 * 4\n",
    "    - batch_size = effective_batch_size / num_generations = 64 / 8 = 8\n",
    "    - steps: len * epochs / batch_size = 200 * 3 / 8 = 75\n",
    "- `_get_train_sampler`\n",
    "    - num_processes: 3, gpu_0, gpu_1, gpu_2\n",
    "    - per_device_train_batch_size: 4\n",
    "    - grad_accum: 3\n",
    "    - num_generations: 3\n",
    "    - batch_size = 4 * 3 * 3 / 3 = 12\n",
    "- `scale_rewards`\n",
    "    - Whether to scale the rewards by dividing them by their standard deviation. If `True` (default), the rewards are normalized by the standard deviation, ensuring they have unit variance. If `False`, no scaling is applied.\n",
    "    - The [Dr. GRPO](https://github.com/sail-sg/understand-r1-zero/blob/main/understand-r1-zero.pdf) paper recommends not scaling the rewards, as scaling by the standard deviation introduces a question-level difficulty bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86c28da-e9bc-489e-a31a-00ec536f07ac",
   "metadata": {},
   "source": [
    "## `_prepare_inputs` & `compute_loss`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fbd66d-0a02-4581-8e40-221b9af62da5",
   "metadata": {},
   "source": [
    "- _prepare_inputs\n",
    "    - prompt_completion_ids: prompt + completion\n",
    "- $-\\beta D_{kl}[\\pi_\\theta\\|\\pi_{ref}]$\n",
    "    - beta: 0.04 (default)\n",
    "    - $\\log \\frac{\\pi_{ref}}{\\pi_\\theta}$ 数值变得有些大时，`exp(log_ratio)` 会指数级爆炸；\n",
    "\n",
    "```python\n",
    "if self.beta != 0.0:\n",
    "    ref_per_token_logps = inputs[\"ref_per_token_logps\"]\n",
    "    per_token_kl = (\n",
    "        torch.exp(ref_per_token_logps - per_token_logps) - (ref_per_token_logps - per_token_logps) - 1\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffce8bc-f4c2-4813-b19a-403e7d54bf8f",
   "metadata": {},
   "source": [
    "### token-level loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9720be89-875e-41ab-9468-822ed109ac06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T12:11:49.283156Z",
     "iopub.status.busy": "2025-03-29T12:11:49.282464Z",
     "iopub.status.idle": "2025-03-29T12:11:49.296640Z",
     "shell.execute_reply": "2025-03-29T12:11:49.293885Z",
     "shell.execute_reply.started": "2025-03-29T12:11:49.283090Z"
    }
   },
   "source": [
    "- https://github.com/huggingface/trl/blob/v0.15.2/trl/trainer/grpo_trainer.py#L719\n",
    "    - per-sequence normalization\n",
    "- https://github.com/huggingface/trl/blob/main/trl/trainer/grpo_trainer.py#L961\n",
    "    - global-norm(token-level)\n",
    "    - each unmasked token's loss provides the same contribution to the total loss.\n",
    "- related\n",
    "    - https://github.com/huggingface/trl/pull/2881/files\n",
    "    - https://x.com/zzlccc/status/1904907968417497202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58636126-6585-4af8-9a34-5dc34eee524b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T23:20:52.938801Z",
     "iopub.status.busy": "2025-03-29T23:20:52.938078Z",
     "iopub.status.idle": "2025-03-29T23:20:54.357314Z",
     "shell.execute_reply": "2025-03-29T23:20:54.356379Z",
     "shell.execute_reply.started": "2025-03-29T23:20:52.938731Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2704113d-3db9-4efe-a1ca-13baa219a3ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T23:21:40.959263Z",
     "iopub.status.busy": "2025-03-29T23:21:40.958795Z",
     "iopub.status.idle": "2025-03-29T23:21:40.968680Z",
     "shell.execute_reply": "2025-03-29T23:21:40.966726Z",
     "shell.execute_reply.started": "2025-03-29T23:21:40.959232Z"
    }
   },
   "outputs": [],
   "source": [
    "per_token_loss = torch.tensor([[1, 2], \n",
    "                               [3, 4], \n",
    "                               [5, 6]])\n",
    "completion_mask = torch.tensor([[1, 1], \n",
    "                                [1, 0], \n",
    "                                [1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45501594-caf5-4aaa-9d37-ddd49d1694d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T23:21:42.111991Z",
     "iopub.status.busy": "2025-03-29T23:21:42.111271Z",
     "iopub.status.idle": "2025-03-29T23:21:42.139598Z",
     "shell.execute_reply": "2025-03-29T23:21:42.137301Z",
     "shell.execute_reply.started": "2025-03-29T23:21:42.111924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1667)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ppo(rlhf) loss\n",
    "grpo_loss = ((per_token_loss * completion_mask).sum(dim=1) / completion_mask.sum(dim=1)).mean()\n",
    "grpo_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56d41bd5-0cc3-40b2-a696-1cf9b8bd9fdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T23:21:54.876610Z",
     "iopub.status.busy": "2025-03-29T23:21:54.875826Z",
     "iopub.status.idle": "2025-03-29T23:21:54.894180Z",
     "shell.execute_reply": "2025-03-29T23:21:54.891846Z",
     "shell.execute_reply.started": "2025-03-29T23:21:54.876537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7500)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_grpo_loss = (per_token_loss * completion_mask).sum() / completion_mask.sum()\n",
    "dr_grpo_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "095afcc5-7f78-4377-afe8-2399b4fa318d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T23:59:39.359526Z",
     "iopub.status.busy": "2025-03-29T23:59:39.358760Z",
     "iopub.status.idle": "2025-03-29T23:59:39.376657Z",
     "shell.execute_reply": "2025-03-29T23:59:39.374252Z",
     "shell.execute_reply.started": "2025-03-29T23:59:39.359456Z"
    }
   },
   "outputs": [],
   "source": [
    "# mean(row_sum(loss * mask)/row_sum(mask)) -> 906\n",
    "# gets a higher loss vs\n",
    "# sum(loss * mask)/sum(mask) -> 727\n",
    "\n",
    "# extremely imbalanced losses and extremely imbalanced completion lengths\n",
    "per_token_loss = torch.tensor([[1000, 1, 1, 1], \n",
    "                               [1000, 1, 1, 1], \n",
    "                               [1000, 1, 1, 1],\n",
    "                               [1000, 1, 1, 1],\n",
    "                               [1000, 1, 1, 1], \n",
    "                               [1000, 1, 1, 1], \n",
    "                               [1000, 1, 1, 1],\n",
    "                               [1000, 1, 1, 1]])\n",
    "completion_mask = torch.tensor([[1, 1, 1, 1], \n",
    "                                [1, 0, 0, 0], \n",
    "                                [1, 0, 0, 0], \n",
    "                                [1, 0, 0, 0], \n",
    "                                [1, 0, 0, 0], \n",
    "                                [1, 0, 0, 0], \n",
    "                                [1, 0, 0, 0], \n",
    "                                [1, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "424f45ef-ec8b-4721-8904-6b1711aa7165",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T23:59:14.375066Z",
     "iopub.status.busy": "2025-03-29T23:59:14.374320Z",
     "iopub.status.idle": "2025-03-29T23:59:14.391936Z",
     "shell.execute_reply": "2025-03-29T23:59:14.389574Z",
     "shell.execute_reply.started": "2025-03-29T23:59:14.374996Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(906.3438)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grpo_loss = ((per_token_loss * completion_mask).sum(dim=1) / completion_mask.sum(dim=1)).mean()\n",
    "grpo_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74a21a51-d723-482e-a39f-b6cf87a3df2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T23:59:20.204066Z",
     "iopub.status.busy": "2025-03-29T23:59:20.203365Z",
     "iopub.status.idle": "2025-03-29T23:59:20.220260Z",
     "shell.execute_reply": "2025-03-29T23:59:20.217739Z",
     "shell.execute_reply.started": "2025-03-29T23:59:20.203998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(727.5455)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_grpo_loss = (per_token_loss * completion_mask).sum() / completion_mask.sum()\n",
    "dr_grpo_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe7f5cdf-6f30-4836-8866-cae86aa71970",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T00:05:45.805807Z",
     "iopub.status.busy": "2025-03-30T00:05:45.805145Z",
     "iopub.status.idle": "2025-03-30T00:05:45.826999Z",
     "shell.execute_reply": "2025-03-30T00:05:45.824699Z",
     "shell.execute_reply.started": "2025-03-30T00:05:45.805737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_token_loss = torch.ones_like(torch.empty(8, 4096))\n",
    "per_token_loss[:, 0] = 1000\n",
    "# per_token_loss\n",
    "completion_mask = torch.zeros_like(torch.empty(8, 4096))\n",
    "completion_mask[0, :] = 1\n",
    "completion_mask[:, 0] = 1\n",
    "completion_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "846bb6da-632b-4722-ab35-cbe45f966110",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T00:05:52.065435Z",
     "iopub.status.busy": "2025-03-30T00:05:52.064398Z",
     "iopub.status.idle": "2025-03-30T00:05:52.088275Z",
     "shell.execute_reply": "2025-03-30T00:05:52.085767Z",
     "shell.execute_reply.started": "2025-03-30T00:05:52.065323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(875.1555)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grpo_loss = ((per_token_loss * completion_mask).sum(dim=1) / completion_mask.sum(dim=1)).mean()\n",
    "grpo_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "733cd793-339d-4e3b-8ce6-573ee4d2c4a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T00:06:09.546526Z",
     "iopub.status.busy": "2025-03-30T00:06:09.545727Z",
     "iopub.status.idle": "2025-03-30T00:06:09.563048Z",
     "shell.execute_reply": "2025-03-30T00:06:09.560567Z",
     "shell.execute_reply.started": "2025-03-30T00:06:09.546455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9478)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(per_token_loss * completion_mask).sum() / completion_mask.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c12dc7-1bf0-4228-9ca5-c1ff4406f167",
   "metadata": {},
   "source": [
    "### verl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c0f301-9399-466a-a8c9-06dfe134bf62",
   "metadata": {},
   "source": [
    "- 默认开启的就是 token-level loss （global mean）\n",
    "\n",
    "    ```python\n",
    "    \n",
    "    def masked_mean(values, mask, axis=None):\n",
    "        \"\"\"Compute mean of tensor with a masked values.\"\"\"\n",
    "        return (values * mask).sum(axis=axis) / mask.sum(axis=axis)\n",
    "    \n",
    "    def compute_policy_loss(old_log_prob, log_prob, advantages, eos_mask, cliprange):\n",
    "        \"\"\"Adapted from https://github.com/huggingface/trl/blob/main/trl/trainer/ppo_trainer.py#L1122\n",
    "    \n",
    "        Args:\n",
    "            old_log_prob: `(torch.Tensor)`\n",
    "                shape: (bs, response_length)\n",
    "            log_prob: `(torch.Tensor)`\n",
    "                shape: (bs, response_length)\n",
    "            advantages: `(torch.Tensor)`\n",
    "                shape: (bs, response_length)\n",
    "            eos_mask: `(torch.Tensor)`\n",
    "                shape: (bs, response_length)\n",
    "            cliprange: (float)\n",
    "                The clip range used in PPO. See https://arxiv.org/abs/1707.06347\n",
    "    \n",
    "        Returns:\n",
    "            pg_loss: `a scalar torch.Tensor`\n",
    "                policy gradient loss computed via PPO\n",
    "            pg_clipfrac: (float)\n",
    "                a float number indicating the fraction of policy gradient loss being clipped\n",
    "    \n",
    "        \"\"\"\n",
    "        negative_approx_kl = log_prob - old_log_prob\n",
    "        ratio = torch.exp(negative_approx_kl)\n",
    "        ppo_kl = verl_F.masked_mean(-negative_approx_kl, eos_mask)\n",
    "    \n",
    "        pg_losses = -advantages * ratio\n",
    "        pg_losses2 = -advantages * torch.clamp(ratio, 1.0 - cliprange, 1.0 + cliprange)\n",
    "    \n",
    "        pg_loss = verl_F.masked_mean(torch.max(pg_losses, pg_losses2), eos_mask)\n",
    "        pg_clipfrac = verl_F.masked_mean(torch.gt(pg_losses2, pg_losses).float(), eos_mask)\n",
    "        return pg_loss, pg_clipfrac, ppo_kl\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536e1972-3d34-4d5e-a6af-e2762e9b76db",
   "metadata": {},
   "source": [
    "## MISC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5468d0a-bc70-4146-8937-894c551cfeaf",
   "metadata": {},
   "source": [
    "- wandb\n",
    "    - `report_to='wandb'`\n",
    "    - 默认的 wandb project 为 huggingface\n",
    "        - `export WANDB_PROJECT=my_prpject_name`\n",
    "- use_vllm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verl",
   "language": "python",
   "name": "verl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
