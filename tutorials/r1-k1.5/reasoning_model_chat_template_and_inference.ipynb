{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f725cbf-889c-4be4-a7e1-bef3c55dd959",
   "metadata": {},
   "source": [
    "> 不要排斥基础，觉得简单。越是复杂的系统，越要从基础从原理及其对应的搞起；\n",
    "- 不只是 tokenize，还有 chat template，什么时候轮到 llm 输出，如何区分 user 和 assistant（包括这期要介绍的 reasoning tokenizer）；\n",
    "    - fancy 和 powerful 的 llm，似乎 tokenizer 很 low level，显得很没有意思，甚至繁琐；\n",
    "    - chat temaplte (for chat models, 目前的 reasoning models 首先也得是一个 chat models)\n",
    "        - 解析历史对话；\n",
    "        - 添加 system prompt，如果用户没有显示地传入的话\n",
    "        - 添加特殊 token id，标记身份，标记 tool；\n",
    "            - tool_call，tool_response（也是一种身份）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dd2d98e-ec23-4369-ab18-2aa194bb2eff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T15:42:54.162804Z",
     "iopub.status.busy": "2025-02-27T15:42:54.162199Z",
     "iopub.status.idle": "2025-02-27T15:42:56.693480Z",
     "shell.execute_reply": "2025-02-27T15:42:56.692591Z",
     "shell.execute_reply.started": "2025-02-27T15:42:54.162754Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import re\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bcb93d1-2fe4-4358-a036-d78f4e34ea1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T15:42:57.393839Z",
     "iopub.status.busy": "2025-02-27T15:42:57.393571Z",
     "iopub.status.idle": "2025-02-27T15:42:57.398179Z",
     "shell.execute_reply": "2025-02-27T15:42:57.397217Z",
     "shell.execute_reply.started": "2025-02-27T15:42:57.393824Z"
    }
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "    \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    \"Qwen/Qwen2.5-Math-1.5B\",\n",
    "    \"Qwen/Qwen2.5-1.5B\",\n",
    "    \"Qwen/QwQ-32B-Preview\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8887e5e-adeb-4b71-9fda-c4d4f41b9226",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T15:42:58.856803Z",
     "iopub.status.busy": "2025-02-27T15:42:58.856090Z",
     "iopub.status.idle": "2025-02-27T15:42:58.865577Z",
     "shell.execute_reply": "2025-02-27T15:42:58.864146Z",
     "shell.execute_reply.started": "2025-02-27T15:42:58.856759Z"
    }
   },
   "outputs": [],
   "source": [
    "def hf_tokenizer(name_or_path):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(name_or_path)\n",
    "    if tokenizer.pad_token_id is None:\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "        print(f'tokenizer.pad_token_id is None. Now set to {tokenizer.eos_token_id}')\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        print(f'tokenizer.pad_token is None. Now set to {tokenizer.eos_token}')\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b47a84-15f8-4bae-849e-87c239146e3a",
   "metadata": {},
   "source": [
    "## tokenizer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f927115b-1a53-460d-a05d-00b9bb31a923",
   "metadata": {},
   "source": [
    "- DeepSeek-R1-Distill-Qwen-1.5B 由  Qwen2.5-Math-1.5B 蒸馏而来，而不是 Qwen/Qwen2.5-1.5B-Instruct；\n",
    "- 复用了词表，重新定义了一些特殊的 token id；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f0cd09a-d29b-4f8c-b33e-34352a77cc88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T15:43:00.300130Z",
     "iopub.status.busy": "2025-02-27T15:43:00.298843Z",
     "iopub.status.idle": "2025-02-27T15:43:00.306383Z",
     "shell.execute_reply": "2025-02-27T15:43:00.305087Z",
     "shell.execute_reply.started": "2025-02-27T15:43:00.300082Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_tokenizer(tokenizer, text):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    print(f'{text}, tokens: {tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29b4875c-ac69-4665-b9eb-def7ba3e1de6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T15:43:17.250875Z",
     "iopub.status.busy": "2025-02-27T15:43:17.250554Z",
     "iopub.status.idle": "2025-02-27T15:43:21.249079Z",
     "shell.execute_reply": "2025-02-27T15:43:21.247425Z",
     "shell.execute_reply.started": "2025-02-27T15:43:17.250851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B, tokenizer.pad_token: <｜end▁of▁sentence｜>, tokenizer.pad_token_id: 151643\n",
      "hello world, tokens: [151646, 14990, 1879]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Qwen/Qwen2.5-1.5B-Instruct, tokenizer.pad_token: <|endoftext|>, tokenizer.pad_token_id: 151643\n",
      "hello world, tokens: [14990, 1879]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Qwen/Qwen2.5-Math-1.5B, tokenizer.pad_token: <|endoftext|>, tokenizer.pad_token_id: 151643\n",
      "hello world, tokens: [14990, 1879]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Qwen/Qwen2.5-1.5B, tokenizer.pad_token: <|endoftext|>, tokenizer.pad_token_id: 151643\n",
      "hello world, tokens: [14990, 1879]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Qwen/QwQ-32B-Preview, tokenizer.pad_token: <|endoftext|>, tokenizer.pad_token_id: 151643\n",
      "hello world, tokens: [14990, 1879]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name_or_path in models:\n",
    "    tokenizer = hf_tokenizer(name_or_path)\n",
    "    print(f'{name_or_path}, tokenizer.pad_token: {tokenizer.pad_token}, tokenizer.pad_token_id: {tokenizer.pad_token_id}')\n",
    "    test_tokenizer(tokenizer, \"hello world\")\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "090c0d1f-41e0-4893-8c4d-0f399e078ebd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T15:43:55.647709Z",
     "iopub.status.busy": "2025-02-27T15:43:55.647130Z",
     "iopub.status.idle": "2025-02-27T15:43:59.392163Z",
     "shell.execute_reply": "2025-02-27T15:43:59.390198Z",
     "shell.execute_reply.started": "2025-02-27T15:43:55.647661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜>\n",
      "<|object_ref_start|>\n",
      "<|object_ref_start|>\n",
      "<|object_ref_start|>\n",
      "<|object_ref_start|>\n"
     ]
    }
   ],
   "source": [
    "distill_tokenizer = hf_tokenizer('deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B')\n",
    "print(distill_tokenizer.decode(151646))\n",
    "qwen_math_tokenizer = hf_tokenizer('Qwen/Qwen2.5-Math-1.5B')\n",
    "print(qwen_math_tokenizer.decode(151646))\n",
    "qwen_chat_tokenizer = hf_tokenizer('Qwen/Qwen2.5-1.5B-Instruct')\n",
    "print(qwen_chat_tokenizer.decode(151646))\n",
    "qwen_base_tokenizer = hf_tokenizer('Qwen/Qwen2.5-1.5B')\n",
    "print(qwen_base_tokenizer.decode(151646))\n",
    "qwen_reason_tokenizer = hf_tokenizer('Qwen/QwQ-32B-Preview')\n",
    "print(qwen_base_tokenizer.decode(151646))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b908f242-cde9-435f-bd3e-e4d79eeab2be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T15:44:00.478292Z",
     "iopub.status.busy": "2025-02-27T15:44:00.477986Z",
     "iopub.status.idle": "2025-02-27T15:44:00.487488Z",
     "shell.execute_reply": "2025-02-27T15:44:00.486169Z",
     "shell.execute_reply.started": "2025-02-27T15:44:00.478269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[151646, 151644]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distill_tokenizer.encode('<｜User｜>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df7609f5-8c46-4925-b197-912b8c9319d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T15:44:08.047467Z",
     "iopub.status.busy": "2025-02-27T15:44:08.046815Z",
     "iopub.status.idle": "2025-02-27T15:44:08.062028Z",
     "shell.execute_reply": "2025-02-27T15:44:08.059773Z",
     "shell.execute_reply.started": "2025-02-27T15:44:08.047419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([27, 130957, 1474, 130957, 29],\n",
       " [27, 130957, 1474, 130957, 29],\n",
       " [27, 130957, 1474, 130957, 29])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwen_math_tokenizer.encode('<｜User｜>'), qwen_chat_tokenizer.encode('<｜User｜>'), qwen_base_tokenizer.encode('<｜User｜>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0780db8c-e866-4add-950e-b7712feaad55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T15:44:10.347896Z",
     "iopub.status.busy": "2025-02-27T15:44:10.347295Z",
     "iopub.status.idle": "2025-02-27T15:44:10.359595Z",
     "shell.execute_reply": "2025-02-27T15:44:10.357401Z",
     "shell.execute_reply.started": "2025-02-27T15:44:10.347849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<｜end▁of▁sentence｜>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is <｜end▁of▁sentence｜>\n",
    "# https://chat.deepseek.com/a/chat/s/569c8476-7b64-48fa-865b-9e01718b961b\n",
    "# what is <|im_end|>\n",
    "# https://chat.qwen.ai/c/da88d4f3-c279-4851-acbb-d3f051c11e86\n",
    "distill_tokenizer.decode(151643)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7713b696-fec9-4d2e-bbe6-5fdbb1989731",
   "metadata": {},
   "source": [
    "## chat template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9e2fac5-0b65-4380-b99a-7fac6a6fbe0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T16:13:27.169612Z",
     "iopub.status.busy": "2025-02-26T16:13:27.169442Z",
     "iopub.status.idle": "2025-02-26T16:13:28.372119Z",
     "shell.execute_reply": "2025-02-26T16:13:28.371018Z",
     "shell.execute_reply.started": "2025-02-26T16:13:27.169598Z"
    }
   },
   "outputs": [],
   "source": [
    "AutoTokenizer.from_pretrained('meta-llama/Llama-3.1-8B').chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1127d0a-9a5b-4c8a-baca-aac993652205",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T16:13:28.373812Z",
     "iopub.status.busy": "2025-02-26T16:13:28.373428Z",
     "iopub.status.idle": "2025-02-26T16:13:28.378985Z",
     "shell.execute_reply": "2025-02-26T16:13:28.378101Z",
     "shell.execute_reply.started": "2025-02-26T16:13:28.373795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{%- if tools %}\n",
      "    {{- '<|im_start|>system\\n' }}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- messages[0]['content'] }}\n",
      "    {%- else %}\n",
      "        {{- 'You are a helpful assistant.' }}\n",
      "    {%- endif %}\n",
      "    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n",
      "    {%- for tool in tools %}\n",
      "        {{- \"\\n\" }}\n",
      "        {{- tool | tojson }}\n",
      "    {%- endfor %}\n",
      "    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n",
      "{%- else %}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n",
      "    {%- else %}\n",
      "        {{- '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- for message in messages %}\n",
      "    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n",
      "        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n",
      "    {%- elif message.role == \"assistant\" %}\n",
      "        {{- '<|im_start|>' + message.role }}\n",
      "        {%- if message.content %}\n",
      "            {{- '\\n' + message.content }}\n",
      "        {%- endif %}\n",
      "        {%- for tool_call in message.tool_calls %}\n",
      "            {%- if tool_call.function is defined %}\n",
      "                {%- set tool_call = tool_call.function %}\n",
      "            {%- endif %}\n",
      "            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n",
      "            {{- tool_call.name }}\n",
      "            {{- '\", \"arguments\": ' }}\n",
      "            {{- tool_call.arguments | tojson }}\n",
      "            {{- '}\\n</tool_call>' }}\n",
      "        {%- endfor %}\n",
      "        {{- '<|im_end|>\\n' }}\n",
      "    {%- elif message.role == \"tool\" %}\n",
      "        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n",
      "            {{- '<|im_start|>user' }}\n",
      "        {%- endif %}\n",
      "        {{- '\\n<tool_response>\\n' }}\n",
      "        {{- message.content }}\n",
      "        {{- '\\n</tool_response>' }}\n",
      "        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n",
      "            {{- '<|im_end|>\\n' }}\n",
      "        {%- endif %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|im_start|>assistant\\n' }}\n",
      "{%- endif %}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We do not recommend using base language models for conversations. Instead, you can apply post-training, e.g., SFT, RLHF, continued pretraining, etc., on this model.\n",
    "# https://huggingface.co/Qwen/Qwen2.5-1.5B\n",
    "print(qwen_base_tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7a5315-ed70-4af3-8fcf-e6fa11a7be76",
   "metadata": {},
   "source": [
    "### distill tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d11103a-dfb7-443e-8093-06a96dad8e5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T16:13:28.379821Z",
     "iopub.status.busy": "2025-02-26T16:13:28.379649Z",
     "iopub.status.idle": "2025-02-26T16:13:28.391739Z",
     "shell.execute_reply": "2025-02-26T16:13:28.390927Z",
     "shell.execute_reply.started": "2025-02-26T16:13:28.379807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='') %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set ns.system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- set ns.is_first = true -%}{%- else %}{{'\\\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<｜tool▁call▁end｜>'}}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set content = content.split('</think>')[-1] %}{% endif %}{{'<｜Assistant｜>' + content + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\\\\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<｜Assistant｜><think>\\\\n'}}{% endif %}\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distill_tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748e6d60-0c94-4106-9660-ea5229e78f9e",
   "metadata": {},
   "source": [
    "```jinja\n",
    "{% if not add_generation_prompt is defined %}\n",
    "    {% set add_generation_prompt = false %}\n",
    "{% endif %}\n",
    "\n",
    "{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='') %}\n",
    "\n",
    "{%- for message in messages %}\n",
    "    {%- if message['role'] == 'system' %}\n",
    "        {% set ns.system_prompt = message['content'] %}\n",
    "    {%- endif %}\n",
    "{%- endfor %}\n",
    "\n",
    "{{bos_token}}{{ns.system_prompt}}\n",
    "\n",
    "{%- for message in messages %}\n",
    "    {%- if message['role'] == 'user' %}\n",
    "        {%- set ns.is_tool = false -%}\n",
    "        {{'<｜User｜>' + message['content']}}\n",
    "    {%- endif %}\n",
    "\n",
    "    {%- if message['role'] == 'assistant' and message['content'] is none %}\n",
    "        {%- set ns.is_tool = false -%}\n",
    "        {%- for tool in message['tool_calls']%}\n",
    "            {%- if not ns.is_first %}\n",
    "                {{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}\n",
    "                {%- set ns.is_first = true -%}\n",
    "            {%- else %}\n",
    "                {{'\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}\n",
    "                {{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}\n",
    "            {%- endif %}\n",
    "        {%- endfor %}\n",
    "    {%- endif %}\n",
    "\n",
    "    {%- if message['role'] == 'assistant' and message['content'] is not none %}\n",
    "        {%- if ns.is_tool %}\n",
    "            {{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}\n",
    "            {%- set ns.is_tool = false -%}\n",
    "        {%- else %}\n",
    "            {% set content = message['content'] %}\n",
    "            {% if '</think>' in content %}\n",
    "                {% set content = content.split('</think>')[-1] %}\n",
    "            {% endif %}\n",
    "            {{'<｜Assistant｜>' + content + '<｜end▁of▁sentence｜>'}}\n",
    "        {%- endif %}\n",
    "    {%- endif %}\n",
    "\n",
    "    {%- if message['role'] == 'tool' %}\n",
    "        {%- set ns.is_tool = true -%}\n",
    "        {%- if ns.is_output_first %}\n",
    "            {{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}\n",
    "            {%- set ns.is_output_first = false %}\n",
    "        {%- else %}\n",
    "            {{'\\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}\n",
    "        {%- endif %}\n",
    "    {%- endif %}\n",
    "{%- endfor -%}\n",
    "\n",
    "{% if ns.is_tool %}\n",
    "    {{'<｜tool▁outputs▁end｜>'}}\n",
    "{% endif %}\n",
    "\n",
    "{% if add_generation_prompt and not ns.is_tool %}\n",
    "    {{'<｜Assistant｜><think>\\n'}}\n",
    "{% endif %}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7afc458-5289-40cb-8408-9b67e0a8bcc3",
   "metadata": {},
   "source": [
    "### qwen tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42be454f-b7ac-4cc9-86a2-0c5f0e3d5d54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T15:52:12.788612Z",
     "iopub.status.busy": "2025-02-27T15:52:12.788121Z",
     "iopub.status.idle": "2025-02-27T15:52:12.797194Z",
     "shell.execute_reply": "2025-02-27T15:52:12.794992Z",
     "shell.execute_reply.started": "2025-02-27T15:52:12.788572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{%- if tools %}\n",
      "    {{- '<|im_start|>system\\n' }}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- messages[0]['content'] }}\n",
      "    {%- else %}\n",
      "        {{- 'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.' }}\n",
      "    {%- endif %}\n",
      "    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n",
      "    {%- for tool in tools %}\n",
      "        {{- \"\\n\" }}\n",
      "        {{- tool | tojson }}\n",
      "    {%- endfor %}\n",
      "    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n",
      "{%- else %}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n",
      "    {%- else %}\n",
      "        {{- '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- for message in messages %}\n",
      "    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n",
      "        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n",
      "    {%- elif message.role == \"assistant\" %}\n",
      "        {{- '<|im_start|>' + message.role }}\n",
      "        {%- if message.content %}\n",
      "            {{- '\\n' + message.content }}\n",
      "        {%- endif %}\n",
      "        {%- for tool_call in message.tool_calls %}\n",
      "            {%- if tool_call.function is defined %}\n",
      "                {%- set tool_call = tool_call.function %}\n",
      "            {%- endif %}\n",
      "            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n",
      "            {{- tool_call.name }}\n",
      "            {{- '\", \"arguments\": ' }}\n",
      "            {{- tool_call.arguments | tojson }}\n",
      "            {{- '}\\n</tool_call>' }}\n",
      "        {%- endfor %}\n",
      "        {{- '<|im_end|>\\n' }}\n",
      "    {%- elif message.role == \"tool\" %}\n",
      "        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n",
      "            {{- '<|im_start|>user' }}\n",
      "        {%- endif %}\n",
      "        {{- '\\n<tool_response>\\n' }}\n",
      "        {{- message.content }}\n",
      "        {{- '\\n</tool_response>' }}\n",
      "        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n",
      "            {{- '<|im_end|>\\n' }}\n",
      "        {%- endif %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|im_start|>assistant\\n' }}\n",
      "{%- endif %}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# default system prompt\n",
    "print(qwen_chat_tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d59e93cb-b1df-4f2f-94cc-ff58551e54c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T16:16:52.137518Z",
     "iopub.status.busy": "2025-02-27T16:16:52.136943Z",
     "iopub.status.idle": "2025-02-27T16:16:52.147070Z",
     "shell.execute_reply": "2025-02-27T16:16:52.144803Z",
     "shell.execute_reply.started": "2025-02-27T16:16:52.137470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{%- if tools %}\n",
      "    {{- '<|im_start|>system\\n' }}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- messages[0]['content'] }}\n",
      "    {%- else %}\n",
      "        {{- 'You are a helpful and harmless assistant. You are Qwen developed by Alibaba. You should think step-by-step.' }}\n",
      "    {%- endif %}\n",
      "    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n",
      "    {%- for tool in tools %}\n",
      "        {{- \"\\n\" }}\n",
      "        {{- tool | tojson }}\n",
      "    {%- endfor %}\n",
      "    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n",
      "{%- else %}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n",
      "    {%- else %}\n",
      "        {{- '<|im_start|>system\\nYou are a helpful and harmless assistant. You are Qwen developed by Alibaba. You should think step-by-step.<|im_end|>\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- for message in messages %}\n",
      "    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n",
      "        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n",
      "    {%- elif message.role == \"assistant\" %}\n",
      "        {{- '<|im_start|>' + message.role }}\n",
      "        {%- if message.content %}\n",
      "            {{- '\\n' + message.content }}\n",
      "        {%- endif %}\n",
      "        {%- for tool_call in message.tool_calls %}\n",
      "            {%- if tool_call.function is defined %}\n",
      "                {%- set tool_call = tool_call.function %}\n",
      "            {%- endif %}\n",
      "            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n",
      "            {{- tool_call.name }}\n",
      "            {{- '\", \"arguments\": ' }}\n",
      "            {{- tool_call.arguments | tojson }}\n",
      "            {{- '}\\n</tool_call>' }}\n",
      "        {%- endfor %}\n",
      "        {{- '<|im_end|>\\n' }}\n",
      "    {%- elif message.role == \"tool\" %}\n",
      "        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n",
      "            {{- '<|im_start|>user' }}\n",
      "        {%- endif %}\n",
      "        {{- '\\n<tool_response>\\n' }}\n",
      "        {{- message.content }}\n",
      "        {{- '\\n</tool_response>' }}\n",
      "        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n",
      "            {{- '<|im_end|>\\n' }}\n",
      "        {%- endif %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|im_start|>assistant\\n' }}\n",
      "{%- endif %}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(qwen_reason_tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3bf83e-7551-406a-90fb-8f2144aa19d4",
   "metadata": {},
   "source": [
    "## apply chat template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f2ff5f3-24e5-49a5-b368-556334ebbd28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T15:44:28.969536Z",
     "iopub.status.busy": "2025-02-27T15:44:28.968869Z",
     "iopub.status.idle": "2025-02-27T15:44:28.979320Z",
     "shell.execute_reply": "2025-02-27T15:44:28.977077Z",
     "shell.execute_reply.started": "2025-02-27T15:44:28.969485Z"
    }
   },
   "outputs": [],
   "source": [
    "basic_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
    "    # {\"role\": \"assistant\", \"content\": \"I'm doing great. How can I help you today?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eccfdbca-1e55-4e93-9214-687b1cef3a66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T16:13:28.410582Z",
     "iopub.status.busy": "2025-02-26T16:13:28.410405Z",
     "iopub.status.idle": "2025-02-26T16:13:28.441275Z",
     "shell.execute_reply": "2025-02-26T16:13:28.440383Z",
     "shell.execute_reply.started": "2025-02-26T16:13:28.410568Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<｜begin▁of▁sentence｜>You are a helpful assistant.<｜User｜>Hello, how are you?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distill_tokenizer.apply_chat_template(basic_messages, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42c3f4d4-fc2b-46fb-affa-50af32b9f80e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T16:13:28.442313Z",
     "iopub.status.busy": "2025-02-26T16:13:28.442117Z",
     "iopub.status.idle": "2025-02-26T16:13:28.447475Z",
     "shell.execute_reply": "2025-02-26T16:13:28.446663Z",
     "shell.execute_reply.started": "2025-02-26T16:13:28.442298Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<｜begin▁of▁sentence｜>You are a helpful assistant.<｜User｜>Hello, how are you?<｜Assistant｜><think>\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\n",
    "distill_tokenizer.apply_chat_template(basic_messages, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae6a1248-b64a-4d36-b1c3-f84d0298df84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T16:13:28.448205Z",
     "iopub.status.busy": "2025-02-26T16:13:28.448035Z",
     "iopub.status.idle": "2025-02-26T16:13:28.466996Z",
     "shell.execute_reply": "2025-02-26T16:13:28.466172Z",
     "shell.execute_reply.started": "2025-02-26T16:13:28.448192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nHello, how are you?<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwen_chat_tokenizer.apply_chat_template(basic_messages, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cb35ff5-aa6c-40a6-aedd-b4cee08b977f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T15:44:44.971108Z",
     "iopub.status.busy": "2025-02-27T15:44:44.970504Z",
     "iopub.status.idle": "2025-02-27T15:44:45.025405Z",
     "shell.execute_reply": "2025-02-27T15:44:45.023217Z",
     "shell.execute_reply.started": "2025-02-27T15:44:44.971060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nHello, how are you?<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwen_reason_tokenizer.apply_chat_template(basic_messages, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8454dd25-25dc-4e0f-8049-abb3ecfc5e5c",
   "metadata": {},
   "source": [
    "## vllm inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c46ca00-bcac-4aa1-a438-9b16c04dc3ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T16:13:28.467886Z",
     "iopub.status.busy": "2025-02-26T16:13:28.467698Z",
     "iopub.status.idle": "2025-02-26T16:13:28.471744Z",
     "shell.execute_reply": "2025-02-26T16:13:28.470932Z",
     "shell.execute_reply.started": "2025-02-26T16:13:28.467871Z"
    }
   },
   "outputs": [],
   "source": [
    "gsm8k_inference_test = \"Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\"\n",
    "gt_ans = '18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9358ee4a-134e-4a7e-bcd1-8d615648cd6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T16:13:28.472682Z",
     "iopub.status.busy": "2025-02-26T16:13:28.472498Z",
     "iopub.status.idle": "2025-02-26T16:13:28.485219Z",
     "shell.execute_reply": "2025-02-26T16:13:28.484074Z",
     "shell.execute_reply.started": "2025-02-26T16:13:28.472667Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<｜begin▁of▁sentence｜><｜Assistant｜><think>\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distill_tokenizer.apply_chat_template([gsm8k_inference_test], add_generation_prompt=True, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80342aa3-8d10-43ce-93ac-379fb60998d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T16:13:28.486300Z",
     "iopub.status.busy": "2025-02-26T16:13:28.486104Z",
     "iopub.status.idle": "2025-02-26T16:13:28.497896Z",
     "shell.execute_reply": "2025-02-26T16:13:28.497007Z",
     "shell.execute_reply.started": "2025-02-26T16:13:28.486285Z"
    }
   },
   "outputs": [],
   "source": [
    "instruction = \"Let's think step by step and output the final answer within \\\\boxed{}.\"\n",
    "chat_test = [{'role': 'user', 'content': f'{gsm8k_inference_test} {instruction}'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f6cdee7-052d-41b8-b471-b5a2ae8289f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T16:13:28.501679Z",
     "iopub.status.busy": "2025-02-26T16:13:28.501415Z",
     "iopub.status.idle": "2025-02-26T16:13:28.508370Z",
     "shell.execute_reply": "2025-02-26T16:13:28.507472Z",
     "shell.execute_reply.started": "2025-02-26T16:13:28.501659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': \"Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market? Let's think step by step and output the final answer within \\\\boxed{}.\"}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0b23bd4-3cc8-48e4-b30a-dbeb8ee06156",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T16:13:28.509476Z",
     "iopub.status.busy": "2025-02-26T16:13:28.509217Z",
     "iopub.status.idle": "2025-02-26T16:13:28.517696Z",
     "shell.execute_reply": "2025-02-26T16:13:28.516781Z",
     "shell.execute_reply.started": "2025-02-26T16:13:28.509453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<｜begin▁of▁sentence｜><｜User｜>Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market? Let's think step by step and output the final answer within \\\\boxed{}.<｜Assistant｜><think>\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distill_tokenizer.apply_chat_template(chat_test, add_generation_prompt=True, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0d0a4ea-4df0-4541-a426-3c80719923bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T16:16:33.543634Z",
     "iopub.status.busy": "2025-02-26T16:16:33.543031Z",
     "iopub.status.idle": "2025-02-26T16:16:33.553022Z",
     "shell.execute_reply": "2025-02-26T16:16:33.551493Z",
     "shell.execute_reply.started": "2025-02-26T16:16:33.543591Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_ids = distill_tokenizer.apply_chat_template(chat_test, add_generation_prompt=True, tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d030e1b-3a53-4191-aa1d-8afcd42090bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T16:15:14.678713Z",
     "iopub.status.busy": "2025-02-26T16:15:14.677637Z",
     "iopub.status.idle": "2025-02-26T16:15:14.684173Z",
     "shell.execute_reply": "2025-02-26T16:15:14.682794Z",
     "shell.execute_reply.started": "2025-02-26T16:15:14.678664Z"
    }
   },
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a631962-b10b-4f37-ae08-b6f1a57bb5a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T16:13:30.986023Z",
     "iopub.status.busy": "2025-02-26T16:13:30.985831Z",
     "iopub.status.idle": "2025-02-26T16:13:58.169590Z",
     "shell.execute_reply": "2025-02-26T16:13:58.168653Z",
     "shell.execute_reply.started": "2025-02-26T16:13:30.986008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-27 00:13:37 llm_engine.py:237] Initializing an LLM engine (vdev) with config: model='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', speculative_config=None, tokenizer='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B, use_v2_block_manager=True, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, mm_processor_kwargs=None)\n",
      "INFO 02-27 00:13:39 model_runner.py:1060] Starting to load model deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B...\n",
      "INFO 02-27 00:13:40 weight_utils.py:243] Using model weights format ['*.safetensors']\n",
      "INFO 02-27 00:13:40 weight_utils.py:288] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a81330624b394ec5adf6982242130d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-27 00:13:41 model_runner.py:1071] Loading model weights took 3.3460 GB\n",
      "INFO 02-27 00:13:43 gpu_executor.py:122] # GPU blocks: 36442, # CPU blocks: 9362\n",
      "INFO 02-27 00:13:43 gpu_executor.py:126] Maximum concurrency for 32768 tokens per request: 17.79x\n",
      "INFO 02-27 00:13:46 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 02-27 00:13:46 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 02-27 00:13:57 model_runner.py:1530] Graph capturing finished in 11 secs.\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(model='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B',\n",
    "        max_model_len=32768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f4c77d6-a113-48c4-a733-be66a3007295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T16:19:38.831563Z",
     "iopub.status.busy": "2025-02-26T16:19:38.830352Z",
     "iopub.status.idle": "2025-02-26T16:19:38.837396Z",
     "shell.execute_reply": "2025-02-26T16:19:38.836095Z",
     "shell.execute_reply.started": "2025-02-26T16:19:38.831518Z"
    }
   },
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(\n",
    "        temperature=0.6, max_tokens=32768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "832e9c16-9b13-4ecb-9211-a2bcf05d1f48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T16:20:01.211695Z",
     "iopub.status.busy": "2025-02-26T16:20:01.210946Z",
     "iopub.status.idle": "2025-02-26T16:20:03.134421Z",
     "shell.execute_reply": "2025-02-26T16:20:03.133506Z",
     "shell.execute_reply.started": "2025-02-26T16:20:01.211652Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.91s/it, est. speed input: 44.52 toks/s, output: 183.84 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First, I need to determine how many eggs Janet has left after she uses some for her own consumption and provides eggs for her friends.\n",
      "\n",
      "Janet’s ducks lay a total of 16 eggs per day. She uses 3 eggs for breakfast and 4 eggs to bake muffins for her friends, so that’s a total of 7 eggs used daily.\n",
      "\n",
      "Subtracting these 7 eggs from the 16 eggs laid, Janet has 9 eggs remaining.\n",
      "\n",
      "Each of these 9 eggs is sold at $2 per egg at the farmers' market. Therefore, multiplying the number of eggs by the selling price gives the total revenue for the day.\n",
      "\n",
      "Finally, multiplying 9 eggs by $2 per egg results in $18, which is the amount Janet makes every day at the farmers' market.\n",
      "</think>\n",
      "\n",
      "**Solution:**\n",
      "\n",
      "1. **Total Eggs Laid Daily:**\n",
      "   - Janet's ducks lay **16 eggs** per day.\n",
      "\n",
      "2. **Eggs Consumed:**\n",
      "   - **Breakfast:** She uses **3 eggs** for breakfast.\n",
      "   - **Muffins:** She bakes **4 eggs** for her friends.\n",
      "   - **Total Consumed:** \\(3 + 4 = 7\\) eggs.\n",
      "\n",
      "3. **Eggs Left for Sale:**\n",
      "   - **Remaining Eggs:** \\(16 - 7 = 9\\) eggs.\n",
      "\n",
      "4. **Revenue from Sells:**\n",
      "   - She sells the remaining **9 eggs** at **\\$2 per egg**.\n",
      "   - **Total Revenue:** \\(9 \\text{ eggs} \\times \\$2/\\text{egg} = \\$18\\).\n",
      "\n",
      "**Final Answer:**\n",
      "\n",
      "\\boxed{18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "response = llm.generate(prompt_token_ids=prompt_ids, sampling_params=sampling_params)[0]\n",
    "print(response.outputs[0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
