{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27d57c1a-9401-413e-99de-46c1feac39bb",
   "metadata": {},
   "source": [
    "- https://www.youtube.com/watch?v=o_g9JUMw1Oc&list=PLJV_el3uVTsODxQFgzMzPLa16h6B8kWM_&index=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40acfbe8-9cd1-4d3e-bca8-5b5e8443e58f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T09:27:38.562662Z",
     "iopub.status.busy": "2025-04-13T09:27:38.561926Z",
     "iopub.status.idle": "2025-04-13T09:27:38.572043Z",
     "shell.execute_reply": "2025-04-13T09:27:38.570229Z",
     "shell.execute_reply.started": "2025-04-13T09:27:38.562592Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847002cb-dbf2-4a31-9adf-a97cec8f86cd",
   "metadata": {},
   "source": [
    "- sarsa: $S_t,A_t,R_t,S_{t+1},A_{t+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53a0f4d7-25aa-404b-ac92-fd5ac98ac687",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T09:27:50.505648Z",
     "iopub.status.busy": "2025-04-13T09:27:50.503761Z",
     "iopub.status.idle": "2025-04-13T09:27:50.525503Z",
     "shell.execute_reply": "2025-04-13T09:27:50.523734Z",
     "shell.execute_reply.started": "2025-04-13T09:27:50.505567Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./figs/q-learning-sarsa.jpeg\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='./figs/q-learning-sarsa.jpeg', width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b059b098-d9fd-4d1b-976f-03aecd4373c7",
   "metadata": {},
   "source": [
    "## Critic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c14b23-7465-4700-b90c-e1272f54da1d",
   "metadata": {},
   "source": [
    "- q-learning 是 value-based methods\n",
    "    - $V^\\pi(s)$，状态的价值，是跟 actor（$\\pi$）有关的；\n",
    "        - 有些落子，对不同棋力的棋手而言，价值是不同的；\n",
    "- how to estimate $V^\\pi(s)$\n",
    "    - Monte-Carlo (MC) based approach, the critic watches $\\pi$ playing the game\n",
    "        - after seeing $s_a$, until the end of the episode, the cumulated reward is $G_a$\n",
    "        - after seeing $s_b$, until the end of the episode, the cumulated reward is $G_b$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verl",
   "language": "python",
   "name": "verl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
