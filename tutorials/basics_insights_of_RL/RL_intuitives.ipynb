{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14050ede-3e8f-487d-b78c-b63f1b1328d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T03:34:56.762823Z",
     "iopub.status.busy": "2025-03-08T03:34:56.762458Z",
     "iopub.status.idle": "2025-03-08T03:34:56.778081Z",
     "shell.execute_reply": "2025-03-08T03:34:56.776471Z",
     "shell.execute_reply.started": "2025-03-08T03:34:56.762791Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f69005-4429-4457-931d-a677f14d033b",
   "metadata": {},
   "source": [
    "https://zhuanlan.zhihu.com/p/17657567877\n",
    "\n",
    "RL 的很多技巧，是围绕着\n",
    "- 训练数据不好生产\n",
    "- 训练数据量太少\n",
    "- 训练数据波动太大\n",
    "- 训练数据分布不均\n",
    "\n",
    "等出发点提出的。\n",
    "\n",
    "- sampling efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c89e50-214f-480d-9439-b2400f62079e",
   "metadata": {},
   "source": [
    "### basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c07c5f-4a2b-4535-9049-7590e93d3c4e",
   "metadata": {},
   "source": [
    "-  online vs. offline\n",
    "> 强化学习 (online) 和传统监督学习(offline)一个很大的区别就是“训练数据是当场采集出来的”，一边造数据，一边训模型，然后用新的模型接着造数据，训模型。\n",
    "- data-driven (imitation) vs. exploration-based methods\n",
    "    - data-driven：requires exponentially more high quality examples to imitate\n",
    "        - SFT无法提供负反馈，举个例子：训练语料为  \"I don't like cat\"，那么P(cat|I don't like)的概率较高，这会顺带让P(cat|I like)的概率也较高，这明显是不符合训练语料逻辑的，这也是产生hallucination的原因之一\n",
    "        - SFT不具备向后看的能力，举个例子：训练语料为  ”深圳是中国首都，这个是错误的“。 如果根据概率模型预测next token（主要是根据上文预测next token），那么P(首都|深圳是中国)的概率会很大，但这明显也不符合训练语料的逻辑；\n",
    "        - SFT的反馈颗粒度是token级别的，每次只会选择next token概率高的，这样做不代表整个text的逻辑就是正确的！\n",
    "    - exploration-based methods:\n",
    "        - precise reward signal efficiently\n",
    "        - build effective RL algos to fully unleash the poential of these signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf013548-3484-476c-92d0-fd9ed03d9683",
   "metadata": {},
   "source": [
    "### Actor-Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f053456c-87bf-4d0d-a988-470b9e54dbc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T03:53:24.066472Z",
     "iopub.status.busy": "2025-03-08T03:53:24.065901Z",
     "iopub.status.idle": "2025-03-08T03:53:24.084671Z",
     "shell.execute_reply": "2025-03-08T03:53:24.082441Z",
     "shell.execute_reply.started": "2025-03-08T03:53:24.066427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://incompleteideas.net/book/ebook/figtmp34.png\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='http://incompleteideas.net/book/ebook/figtmp34.png', width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0cbc0c-b708-489d-8728-f96bcd773f5f",
   "metadata": {},
   "source": [
    "- actor-critic\n",
    "    - critic：价值网络($v(s)$)，如果仅有价值网络，容易贪心，陷入局部左右值；\n",
    "        - critic 单步打分，reward model：最终裁决；\n",
    "        - critic 网络的评价（estimated advantage，优势函数）提供了 actor 的更新方向；\n",
    "        - 优势函数：实际期望 - 预期期望（评价家预测）\n",
    "            - 大于 0，这个策略就值得鼓励；\n",
    "    - actor：策略网络($\\pi(a|s)$)，概率输出，增加探索的可能；\n",
    "    - 两者都需要不断训练；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a4324b-d93c-44c2-a0f9-be49f277c3ed",
   "metadata": {},
   "source": [
    "### GRPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fea519a-d63d-408f-9549-e2d5cbd6f4b9",
   "metadata": {},
   "source": [
    "- update rule: better score increase likelihood"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
