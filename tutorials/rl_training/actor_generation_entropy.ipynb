{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5aa981f-2f12-4a58-af33-a3a06fcd24ab",
   "metadata": {},
   "source": [
    "- (trl) `ppo_trainer.py`\n",
    "```python\n",
    "prob_dist = torch.nn.functional.softmax(logits, dim=-1)\n",
    "entropy = torch.logsumexp(logits, dim=-1) - torch.sum(prob_dist * logits, dim=-1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2ee834-da23-4786-9785-602ac943d548",
   "metadata": {},
   "source": [
    "$$\n",
    "H=-\\sum_vp(v)\\log p(v)\n",
    "$$\n",
    "\n",
    "- 在 llm 中，就是 generation 生成序列的每个位置 $\\pi_\\theta(\\cdot |q, o_{\\lt t})$ 都对应一个词表维度的概率分布\n",
    "\n",
    "$$\n",
    "p(v)=\\frac{\\exp(\\text{logits}_v)}{\\sum_{v'}\\exp(\\text{logits}_{v'})}=\\frac{\\exp(\\text{logits}_v)}{Z}\n",
    "$$\n",
    "\n",
    "- 则有\n",
    "\n",
    "$$\n",
    "\\log p(v)=\\text{logits}_v-\\log Z\n",
    "$$\n",
    "\n",
    "- 进一步\n",
    "\n",
    "$$\n",
    "H=-\\sum_v p(v)\\log p(v)=-\\sum_v p(v)(\\text{logits}_v-\\log Z)=\\log Z - \\sum_v p(v)\\text{logits}_v\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verl",
   "language": "python",
   "name": "verl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
