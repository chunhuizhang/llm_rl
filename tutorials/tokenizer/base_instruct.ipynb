{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ab27e43-c54b-4f14-a795-48b50d2a7677",
   "metadata": {},
   "source": [
    "### completion vs. chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9505bdfc-4646-43f3-9806-d0381295fddd",
   "metadata": {},
   "source": [
    "```python\n",
    "prompt = f\"Q: {question}\\nA:\"\n",
    "\n",
    "# 也可以尝试 few-shot，提供一些例子\n",
    "prompt = f\"\"\"\n",
    "Q: 西班牙的首都是哪里?\n",
    "A: 马德里\n",
    "\n",
    "Q: 德国的首都是哪里?\n",
    "A: 柏林\n",
    "\n",
    "Q: {question}\n",
    "A:\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "```python\n",
    "prompt = f\"<|im_start|>system\\n{system_prompt}<|im_end|>\\n\"\n",
    "prompt += f\"<|im_start|>user\\n{question}<|im_end|>\\n\"\n",
    "prompt += \"<|im_start|>assistant\\n\" # 模型将从这里开始生成\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc9c13f-281d-4bca-979e-f619d60facf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:53:37.729185Z",
     "iopub.status.busy": "2025-04-07T13:53:37.728501Z",
     "iopub.status.idle": "2025-04-07T13:53:40.489191Z",
     "shell.execute_reply": "2025-04-07T13:53:40.487435Z",
     "shell.execute_reply.started": "2025-04-07T13:53:37.729103Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whaow/anaconda3/envs/verl/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4aaec49-7f81-4579-969a-4f2d34633949",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:53:40.490507Z",
     "iopub.status.busy": "2025-04-07T13:53:40.490153Z",
     "iopub.status.idle": "2025-04-07T13:53:42.434175Z",
     "shell.execute_reply": "2025-04-07T13:53:42.432303Z",
     "shell.execute_reply.started": "2025-04-07T13:53:40.490480Z"
    }
   },
   "outputs": [],
   "source": [
    "base_tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen2.5-3B')\n",
    "instruct_tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen2.5-3B-Instruct')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45f97c3-c335-49fd-83ce-fae68641ca32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:06:28.468897Z",
     "iopub.status.busy": "2025-04-07T13:06:28.468196Z",
     "iopub.status.idle": "2025-04-07T13:06:28.479357Z",
     "shell.execute_reply": "2025-04-07T13:06:28.477080Z",
     "shell.execute_reply.started": "2025-04-07T13:06:28.468814Z"
    },
    "scrolled": true
   },
   "source": [
    "print(base_tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe0d0ea4-224f-440e-88fe-7e84c5301d54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:53:42.435556Z",
     "iopub.status.busy": "2025-04-07T13:53:42.435297Z",
     "iopub.status.idle": "2025-04-07T13:53:42.444257Z",
     "shell.execute_reply": "2025-04-07T13:53:42.442867Z",
     "shell.execute_reply.started": "2025-04-07T13:53:42.435531Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_prefix(numbers, target, template_type):\n",
    "    # NOTE: also need to change reward_score/countdown.py\n",
    "    if template_type == 'base':\n",
    "        # follow deepseek-r1-zero\n",
    "        \"\"\"This works for any base model\"\"\"\n",
    "        prefix = f\"\"\"A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer.\n",
    "User: Using the numbers {numbers}, create an equation that equals {target}. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.\n",
    "Assistant: Let me solve this step by step.\n",
    "<think>\"\"\"\n",
    "    elif template_type == 'qwen-instruct':\n",
    "        \"\"\"This works for Qwen Instruct Models\"\"\"\n",
    "        prefix = f\"\"\"<|im_start|>system\\nYou are a helpful assistant. You first thinks about the reasoning process in the mind and then provides the user with the answer.<|im_end|>\\n<|im_start|>user\\n Using the numbers {numbers}, create an equation that equals {target}. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>\"\"\"\n",
    "    return prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4be775a2-f683-40cb-885c-c18fe5cde9ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:53:42.445164Z",
     "iopub.status.busy": "2025-04-07T13:53:42.444916Z",
     "iopub.status.idle": "2025-04-07T13:53:42.469426Z",
     "shell.execute_reply": "2025-04-07T13:53:42.467716Z",
     "shell.execute_reply.started": "2025-04-07T13:53:42.445141Z"
    }
   },
   "outputs": [],
   "source": [
    "numbers = [ 44, 19, 35 ]\n",
    "target = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "957e2b37-09b5-4ed3-9349-26f76d5d1776",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:53:42.470365Z",
     "iopub.status.busy": "2025-04-07T13:53:42.470124Z",
     "iopub.status.idle": "2025-04-07T13:53:42.481654Z",
     "shell.execute_reply": "2025-04-07T13:53:42.480088Z",
     "shell.execute_reply.started": "2025-04-07T13:53:42.470341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer.\n",
      "User: Using the numbers [44, 19, 35], create an equation that equals 99. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.\n",
      "Assistant: Let me solve this step by step.\n",
      "<think>\n"
     ]
    }
   ],
   "source": [
    "base_prompt = make_prefix(numbers, target, 'base')\n",
    "print(base_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63ca8fd3-0681-4a8d-9f01-1c7ca481d295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:53:42.484933Z",
     "iopub.status.busy": "2025-04-07T13:53:42.484625Z",
     "iopub.status.idle": "2025-04-07T13:53:42.492636Z",
     "shell.execute_reply": "2025-04-07T13:53:42.491091Z",
     "shell.execute_reply.started": "2025-04-07T13:53:42.484906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant. You first thinks about the reasoning process in the mind and then provides the user with the answer.<|im_end|>\n",
      "<|im_start|>user\n",
      " Using the numbers [44, 19, 35], create an equation that equals 99. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Let me solve this step by step.\n",
      "<think>\n"
     ]
    }
   ],
   "source": [
    "instruct_prompt = make_prefix(numbers, target, 'qwen-instruct')\n",
    "print(instruct_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051f7f62-38e2-4196-b2c9-2d93ca05ed92",
   "metadata": {},
   "source": [
    "### base model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89b5be01-82b4-4683-a31b-9f00ae234288",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:53:42.493820Z",
     "iopub.status.busy": "2025-04-07T13:53:42.493547Z",
     "iopub.status.idle": "2025-04-07T13:53:45.069592Z",
     "shell.execute_reply": "2025-04-07T13:53:45.067926Z",
     "shell.execute_reply.started": "2025-04-07T13:53:42.493794Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 21:53:44,179\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "/home/whaow/anaconda3/envs/verl/lib/python3.9/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:\n",
      "No module named 'vllm._version'\n",
      "  from vllm.version import __version__ as VLLM_VERSION\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9002bc4-e586-4e9a-9431-ffe58903f705",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:53:45.070820Z",
     "iopub.status.busy": "2025-04-07T13:53:45.070398Z",
     "iopub.status.idle": "2025-04-07T13:54:11.069505Z",
     "shell.execute_reply": "2025-04-07T13:54:11.068459Z",
     "shell.execute_reply.started": "2025-04-07T13:53:45.070790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-07 21:53:52 llm_engine.py:237] Initializing an LLM engine (vdev) with config: model='Qwen/Qwen2.5-3B', speculative_config=None, tokenizer='Qwen/Qwen2.5-3B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=1024, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Qwen/Qwen2.5-3B, use_v2_block_manager=True, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, mm_processor_kwargs=None)\n",
      "INFO 04-07 21:53:54 model_runner.py:1060] Starting to load model Qwen/Qwen2.5-3B...\n",
      "INFO 04-07 21:53:55 weight_utils.py:243] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.42it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.76it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-07 21:53:57 model_runner.py:1071] Loading model weights took 5.7915 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-07 21:53:58 gpu_executor.py:122] # GPU blocks: 25179, # CPU blocks: 7281\n",
      "INFO 04-07 21:53:58 gpu_executor.py:126] Maximum concurrency for 1024 tokens per request: 393.42x\n",
      "INFO 04-07 21:54:00 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 04-07 21:54:00 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 04-07 21:54:10 model_runner.py:1530] Graph capturing finished in 10 secs.\n"
     ]
    }
   ],
   "source": [
    "sampling_params = SamplingParams(\n",
    "    temperature=0.6, \n",
    "    max_tokens=1024\n",
    ")\n",
    "base_llm = LLM(model='Qwen/Qwen2.5-3B', max_model_len=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "027be3ea-6a9a-4fe4-9644-9104814f5f63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:54:11.070370Z",
     "iopub.status.busy": "2025-04-07T13:54:11.070178Z",
     "iopub.status.idle": "2025-04-07T13:54:12.103312Z",
     "shell.execute_reply": "2025-04-07T13:54:12.101392Z",
     "shell.execute_reply.started": "2025-04-07T13:54:11.070351Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it, est. speed input: 139.76 toks/s, output: 111.22 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We need to use the numbers 44, 19, and 35 exactly once to create an equation that equals 99. We can use basic arithmetic operations like addition, subtraction, multiplication, and division. Let's start by looking for patterns or combinations of the numbers that could add up to 99. One way to approach this is to try different operations or combinations of the numbers. </think>\n",
      "The final answer is: <answer> 44 + 35 + 19 = 99 </answer>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_resp = base_llm.generate(base_prompt, sampling_params)[0]\n",
    "print(base_resp.outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d51db9c-786c-418f-9150-efc70f120e93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:54:12.104314Z",
     "iopub.status.busy": "2025-04-07T13:54:12.104056Z",
     "iopub.status.idle": "2025-04-07T13:54:16.045406Z",
     "shell.execute_reply": "2025-04-07T13:54:16.044450Z",
     "shell.execute_reply.started": "2025-04-07T13:54:12.104290Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.93s/it, est. speed input: 1.53 toks/s, output: 115.86 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Beijing.____\n",
      "A. The capital of China is Beijing.\n",
      "B. Beijing is the capital of China.\n",
      "C. The capital of China is Beijing.\n",
      "D. Beijing is the capital of China.\n",
      "Answer:\n",
      "D\n",
      "\n",
      "The most abundant element in the Earth's crust is ____\n",
      "A. Oxygen\n",
      "B. Silicon\n",
      "C. Aluminum\n",
      "D. Iron\n",
      "Answer:\n",
      "A\n",
      "\n",
      "Which of the following explanations of the emphasized words in the sentences is incorrect?\n",
      "A. The reason why loyal ministers and virtuous officials dare not speak, and the reason why fools and traitors dare to speak, is because they are afraid of being punished. Punishment: Punishment.\n",
      "B. If you want to know the truth, I will tell you. Know: Understand.\n",
      "C. In the morning, I cross the river and settle in the west, and by nightfall, I am in the east. Cross: Cross.\n",
      "D. The reason why the old man was able to survive and not perish is the same as me. Pity: Like.\n",
      "Answer:\n",
      "A\n",
      "\n",
      "The starting point of human life is ____\n",
      "A. Fertilized egg\n",
      "B. Embryo\n",
      "C. Infant\n",
      "D. Newborn\n",
      "Answer:\n",
      "A\n",
      "\n",
      "The solution set for the inequality x^{2}-2x-3>0 is ____\n",
      "A. (-1, 3)\n",
      "B. (-∞, -1) ∪ (3, +∞)\n",
      "C. (-3, 1)\n",
      "D. (-∞, -3) ∪ (1, +∞)\n",
      "Answer:\n",
      "B\n",
      "\n",
      "The following table shows the number of naval and air force officers and engineers in the North China Military District from 1948 to 1949. This table reflects that the People's Liberation Army ____. | Year | Number of Naval and Air Force Officers and Engineers | | --- | --- | | 1948 | 2,804 | | 1949 | 3,363 |\n",
      "A. Gradually expanded its scale\n",
      "B. Won many victories in the southern theater\n",
      "C. Had a relatively strong combat capability\n",
      "D. Effectively thwarted the Nationalist army's rearward defense strategy\n",
      "Answer:\n",
      "C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_resp = base_llm.generate('The captail of China is', sampling_params)[0]\n",
    "print(test_resp.outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "967c6270-cff3-4833-a724-96a2a5392eb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:54:16.046153Z",
     "iopub.status.busy": "2025-04-07T13:54:16.045981Z",
     "iopub.status.idle": "2025-04-07T13:54:24.561572Z",
     "shell.execute_reply": "2025-04-07T13:54:24.560599Z",
     "shell.execute_reply.started": "2025-04-07T13:54:16.046136Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.51s/it, est. speed input: 0.35 toks/s, output: 120.17 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tom. I am a student. I am in Class Two, Grade Eight. This is my friend, Jack. He is a student, too. He is in Class One, Grade Eight. My Chinese teacher is Mr. Zhang. He is a good teacher. He likes us very much. My English teacher is Miss. Wang. She is very young. She is good with us. She likes us, too. We like them. 根据短文内容，判断正误（正确的写\"正确\"，错误的写\"错误\"）。 (1). 2. Miss. Wang is a good Chinese teacher. (2). 3. Tom is in Class Two, Grade Eight. (3). 4. Mr. Zhang is Tom's English teacher. (4). 5. Jack and Tom are in the same class. (5). 1. Jack is a student, too.\n",
      "\n",
      "【小题1】错误 【小题2】正确 【小题3】正确 【小题4】错误 【小题5】错误\n",
      "\n",
      "根据汉语意思完成句子。 【 1 】 这个房间是用空气新鲜的木材做的。 This room is made of ___________. 【 2 】 我们必须阻止人们在森林里砍伐树木。 We must _______________ people from cutting down trees in the forest. 【 3 】 请不要把纸屑扔在地板上。 Please don't ___________ the paper on the floor. 【 4 】 环保对我们来说非常重要。 It is ___________ for us to protect the environment. 【 5 】 为了保护我们美丽的地球，我们不能乱扔垃圾。 We can't ___________ rubbish because we must protect our beautiful earth.\n",
      "\n",
      "【 1 】 fresh air 【 2 】 stop 【 3 】 throw away 【 4 】 important 【 5 】 throw away\n",
      "\n",
      "阅读下面的文字，完成下列小题。 雪山 谢大立 10月25日，是红军长征胜利70周年的日子。 一大早，我们一行就匆匆地赶到了雪山脚下。 1936年10月，红军三大主力在甘肃会宁胜利会师，宣告长征胜利结束。但是，虽然红军主力在陕北会师，但还有几支红军队伍在雪山、草地里艰难行军，这一路上，究竟会有多少红军战死在这崇山峻岭中，又有多少红军战士被饥饿折磨得骨瘦如柴，这一切，已永远地被埋葬在万古长青的雪山之上了。 1936年10月，是红军长征胜利70周年的日子。 一大早，我们一行就匆匆地赶到了雪山脚下。 1936年10月，红军三大主力在甘肃会宁胜利会师，宣告长征胜利结束。但是，虽然红军主力在陕北会师，但还有几支红军队伍在雪山、草地里艰难行军，这一路上，究竟会有多少红军战死在这崇山峻岭中，又有多少红军战士被饥饿折磨得骨瘦如柴，这一切，已永远地被埋葬在万古长青的雪山之上了。 1936年10月，是红军长征胜利70周年的日子。 一大早，我们一行就匆匆地赶到了雪山脚下。 1936年10月，红军三大主力在甘肃会宁胜利会师，宣告长征胜利结束。但是，虽然红军主力在陕北会师，但还有几支红军队伍在雪山、草地里艰难行军，这一路上，究竟会有多少红军战死在这崇山峻岭中，又有多少红军战士被饥饿折磨得骨瘦如柴，这一切，已永远地被埋葬在万古长青的雪山之上了。 1936年10月，是红军长征胜利70周年的日子。 一大早，我们一行就匆匆地赶到了雪山脚下。 1936年10月，红军三大主力在甘肃会宁胜利会师，宣告长征胜利结束。但是，虽然红军主力在陕北会师，但还有几支红军队伍在雪山、草地里艰难行军，这一路上，究竟会有多少红军战死在这崇山峻岭中，又有多少红军战士被饥饿折磨得骨瘦如柴，这一切，已永远地被埋葬在万古长青的雪山之上了。 1936年10月，是红军长征胜利70周年的日子。 一大早，我们一行就匆匆地赶到了雪山脚下。 1936年10月，红军三大主力在甘肃会宁胜利会师，宣告长征胜利结束。但是，虽然红军主力在陕北会师，但还有几支红军队伍在雪山、\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_resp = base_llm.generate('My name is', sampling_params)[0]\n",
    "print(test_resp.outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26484c64-80f7-4cea-97c0-0f3f68b19e9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:54:24.562406Z",
     "iopub.status.busy": "2025-04-07T13:54:24.562230Z",
     "iopub.status.idle": "2025-04-07T13:54:33.044939Z",
     "shell.execute_reply": "2025-04-07T13:54:33.043997Z",
     "shell.execute_reply.started": "2025-04-07T13:54:24.562389Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.47s/it, est. speed input: 0.59 toks/s, output: 120.40 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " was a little girl who loved to play in the house. She picked up everything. She put it away, and then she picked it up again. She put it away, and then she picked it up again. Finally, her mother said, \"I'm going to put a sign on the door. Then you won't be able to come in any more.\" \"What sign, Mom?\" \"It'll say, 'Out of Order',\" said her mother. \"Oh,\" said the little girl. Then she went and hid under the bed. A few minutes later, her mother called her, \"Come in here.\" The little girl came out from under the bed. \"What's wrong, Mom?\" \"I put the sign on the door,\" said her mother, \"and I can't open it.\" 【小题1】The little girl picked up everything because she wanted to put it away. 【小题2】The little girl put it away because her mother asked her to do so. 【小题3】The little girl was very angry with her mother. 【小题4】The mother didn't want to play with the little girl. 【小题5】The mother could not open the door because the sign was on it. 【小题1】T 【小题2】F 【小题3】T 【小题4】T 【小题5】T\n",
      "\n",
      "阅读下面的文章，完成后面题目。 《红楼梦》中女性形象的复杂性 一、《红楼梦》中女性形象的复杂性 《红楼梦》中人物众多，女性形象更是丰富多彩。 《红楼梦》中女性形象的复杂性，主要表现在以下方面： 1．女性的阶级性。阶级是社会上最本质、最直接的差别。《红楼梦》中女性形象的阶级性，主要表现在她们所处的社会地位的不同。《红楼梦》中女性形象的阶级性，是决定其性格的重要因素，也是决定其命运的重要因素。 2．女性的性别特征。《红楼梦》中女性形象的性别特征，主要表现在其在性别方面所特有的差异上。 3．女性的文学性。文学性是指作品中人物形象所具有的审美价值和艺术魅力。《红楼梦》中女性形象的文学性，主要表现在以下方面：①《红楼梦》中女性形象的典型性。②《红楼梦》中女性形象的艺术性。 4．女性的象征性。《红楼梦》中女性形象的象征性，主要表现在两个方面：①女性形象的隐喻性。②女性形象的隐喻性。 《红楼梦》中女性形象的复杂性，是个性与共性的统一。个性是指《红楼梦》中女性形象所具有的特殊性。共性是指《红楼梦》中女性形象所具有的普遍性，即《红楼梦》中女性形象所具有的共有的品格、气质、思想、性格等。 总之，《红楼梦》中女性形象的复杂性，是个性与共性的统一，是人物形象与社会现实的统一，是人物形象与民族心理的统一。 (选自《红楼梦论丛》，有改动) 1．下列对《红楼梦》中女性形象复杂性的理解，不正确的一项是 A．《红楼梦》中女性形象的复杂性，主要表现在她们所处的社会地位的不同。 B．《红楼梦》中女性形象的阶级性，是决定其性格和命运的重要因素。 C．《红楼梦》中女性形象的性别特征，主要表现在其在性别方面所特有的差异上。 D．《红楼梦》中女性形象的文学性，主要表现在其典型性和艺术性。 2．下列对《红楼梦》中女性形象复杂性的理解，不正确的一项是 A．《红楼梦》中女性形象的复杂性，是《红楼梦》中人物形象与社会现实的统一。 B．《红楼梦》中女性形象的复杂性，是《红楼梦》中人物形象与民族心理的统一。 C．《红楼梦》中女性形象的复杂性，是《红楼梦》中人物形象个性与共性的统一。 D．《红楼梦》中女性形象的复杂性，是《红楼梦》中人物形象与《红楼梦》中社会现实的统一。 3．下列对《红楼梦》中女性形象复杂性的理解，不正确的一项是 A．《红楼梦》中女性形象的复杂性，是《红楼梦》中人物形象与《红楼梦》中民族心理的统一。 B．《红楼梦》中女性形象的复杂性，是《红楼梦》中人物形象与《红楼梦》中社会现实的统一。 C．《红楼梦》中女性形象的复杂性，是《红楼梦》中人物形象与《红楼梦》中文学性的统一。 D．《红楼梦》中女性形象的复杂性，是《红楼梦》中人物形象与《红楼梦》中阶级\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_resp = base_llm.generate('Long long ago, there', sampling_params)[0]\n",
    "print(test_resp.outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "121a24ef-3c70-4286-962e-b0b1f9fe30b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:54:33.045530Z",
     "iopub.status.busy": "2025-04-07T13:54:33.045366Z",
     "iopub.status.idle": "2025-04-07T13:54:40.437266Z",
     "shell.execute_reply": "2025-04-07T13:54:40.436266Z",
     "shell.execute_reply.started": "2025-04-07T13:54:33.045513Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.38s/it, est. speed input: 18.56 toks/s, output: 120.33 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First, I need to find a way to use the numbers 35 and 19 to get close to 99. I can start by adding 35 and 19, which gives me 54. Then, I can subtract 54 from 99, which gives me 45. Now, I need to find a way to get from 45 to 44. I can subtract 45 by 1, which gives me -1. But that doesn't work because I can't use -1 as a number in my equation. So, I need to find another way to get from 45 to 44. I can divide 45 by 1.1, which gives me 40.90909090909091. Then, I can subtract 40.90909090909091 by 0.9090909090909091, which gives me 40. Now, I need to find a way to get from 40 to 44. I can multiply 40 by 1.1, which gives me 44. But that doesn't work because I can't use 1.1 as a number in my equation. So, I need to find another way to get from 40 to 44. I can add 40 by 0.4, which gives me 40.4. Then, I can subtract 40.4 by 0.4, which gives me 40. But that doesn't work because I can't use 40 as a number in my equation. So, I need to find another way to get from 40 to 44. I can add 40 by 0.4, which gives me 40.4. Then, I can subtract 40.4 by 0.4, which gives me 40. But that doesn't work because I can't use 40 as a number in my equation. So, I need to find another way to get from 40 to 44. I can add 40 by 0.4, which gives me 40.4. Then, I can subtract 40.4 by 0.4, which gives me 40. But that doesn't work because I can't use 40 as a number in my equation. So, I need to find another way to get from 40 to 44. I can add 40 by 0.4, which gives me 40.4. Then, I can subtract 40.4 by 0.4, which gives me 40. But that doesn't work because I can't use 40 as a number in my equation. So, I need to find another way to get from 40 to 44. I can add 40 by 0.4, which gives me 40.4. Then, I can subtract 40.4 by 0.4, which gives me 40. But that doesn't work because I can't use 40 as a number in my equation. So, I need to find another way to get from 40 to 44. I can add 40 by 0.4, which gives me 40.4. Then, I can subtract 40.4 by 0.4, which gives me 40. But that doesn't work because I can't use 40 as a number in my equation. So, I need to find another way to get from 40 to 44. I can add 40 by 0.4, which gives me 40.4. Then, I can subtract 40.4 by 0.4, which gives me 40. But that doesn't work because I can't use 40 as a number in my equation. So, I need to find another way to get from 40 to 44. I can add \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_resp = base_llm.generate(instruct_prompt, sampling_params)[0]\n",
    "print(test_resp.outputs[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fa52ea-90bc-46c9-983e-56effd61b911",
   "metadata": {},
   "source": [
    "### instruct model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8871c49e-66e9-40cc-a0f2-87ddb101a820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:54:40.437840Z",
     "iopub.status.busy": "2025-04-07T13:54:40.437674Z",
     "iopub.status.idle": "2025-04-07T13:54:40.442363Z",
     "shell.execute_reply": "2025-04-07T13:54:40.441492Z",
     "shell.execute_reply.started": "2025-04-07T13:54:40.437823Z"
    }
   },
   "outputs": [],
   "source": [
    "# instruct_llm = LLM(model='Qwen/Qwen2.5-3B-Instruct', max_model_len=1024)\n",
    "# instruct_resp = instruct_llm.generate(instruct_prompt, sampling_params)[0]\n",
    "# print(instruct_resp.outputs[0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verl",
   "language": "python",
   "name": "verl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
