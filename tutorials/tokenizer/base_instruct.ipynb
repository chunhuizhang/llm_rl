{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc9c13f-281d-4bca-979e-f619d60facf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:32:55.258951Z",
     "iopub.status.busy": "2025-04-07T13:32:55.258266Z",
     "iopub.status.idle": "2025-04-07T13:32:58.036613Z",
     "shell.execute_reply": "2025-04-07T13:32:58.034559Z",
     "shell.execute_reply.started": "2025-04-07T13:32:55.258882Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whaow/anaconda3/envs/verl/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4aaec49-7f81-4579-969a-4f2d34633949",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:32:58.038382Z",
     "iopub.status.busy": "2025-04-07T13:32:58.038010Z",
     "iopub.status.idle": "2025-04-07T13:33:01.548187Z",
     "shell.execute_reply": "2025-04-07T13:33:01.546112Z",
     "shell.execute_reply.started": "2025-04-07T13:32:58.038355Z"
    }
   },
   "outputs": [],
   "source": [
    "base_tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen2.5-3B')\n",
    "instruct_tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen2.5-3B-Instruct')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45f97c3-c335-49fd-83ce-fae68641ca32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:06:28.468897Z",
     "iopub.status.busy": "2025-04-07T13:06:28.468196Z",
     "iopub.status.idle": "2025-04-07T13:06:28.479357Z",
     "shell.execute_reply": "2025-04-07T13:06:28.477080Z",
     "shell.execute_reply.started": "2025-04-07T13:06:28.468814Z"
    },
    "scrolled": true
   },
   "source": [
    "print(base_tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe0d0ea4-224f-440e-88fe-7e84c5301d54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:33:01.549195Z",
     "iopub.status.busy": "2025-04-07T13:33:01.548940Z",
     "iopub.status.idle": "2025-04-07T13:33:01.557813Z",
     "shell.execute_reply": "2025-04-07T13:33:01.556336Z",
     "shell.execute_reply.started": "2025-04-07T13:33:01.549170Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_prefix(numbers, target, template_type):\n",
    "    # NOTE: also need to change reward_score/countdown.py\n",
    "    if template_type == 'base':\n",
    "        # follow deepseek-r1-zero\n",
    "        \"\"\"This works for any base model\"\"\"\n",
    "        prefix = f\"\"\"A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer.\n",
    "User: Using the numbers {numbers}, create an equation that equals {target}. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.\n",
    "Assistant: Let me solve this step by step.\n",
    "<think>\"\"\"\n",
    "    elif template_type == 'qwen-instruct':\n",
    "        \"\"\"This works for Qwen Instruct Models\"\"\"\n",
    "        prefix = f\"\"\"<|im_start|>system\\nYou are a helpful assistant. You first thinks about the reasoning process in the mind and then provides the user with the answer.<|im_end|>\\n<|im_start|>user\\n Using the numbers {numbers}, create an equation that equals {target}. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>\"\"\"\n",
    "    return prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4be775a2-f683-40cb-885c-c18fe5cde9ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:33:01.559140Z",
     "iopub.status.busy": "2025-04-07T13:33:01.558877Z",
     "iopub.status.idle": "2025-04-07T13:33:01.575393Z",
     "shell.execute_reply": "2025-04-07T13:33:01.574045Z",
     "shell.execute_reply.started": "2025-04-07T13:33:01.559116Z"
    }
   },
   "outputs": [],
   "source": [
    "numbers = [ 44, 19, 35 ]\n",
    "target = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "957e2b37-09b5-4ed3-9349-26f76d5d1776",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:33:01.577301Z",
     "iopub.status.busy": "2025-04-07T13:33:01.577017Z",
     "iopub.status.idle": "2025-04-07T13:33:01.586205Z",
     "shell.execute_reply": "2025-04-07T13:33:01.584916Z",
     "shell.execute_reply.started": "2025-04-07T13:33:01.577275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer.\n",
      "User: Using the numbers [44, 19, 35], create an equation that equals 99. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.\n",
      "Assistant: Let me solve this step by step.\n",
      "<think>\n"
     ]
    }
   ],
   "source": [
    "base_prompt = make_prefix(numbers, target, 'base')\n",
    "print(base_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63ca8fd3-0681-4a8d-9f01-1c7ca481d295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:33:01.589032Z",
     "iopub.status.busy": "2025-04-07T13:33:01.588681Z",
     "iopub.status.idle": "2025-04-07T13:33:01.596837Z",
     "shell.execute_reply": "2025-04-07T13:33:01.595705Z",
     "shell.execute_reply.started": "2025-04-07T13:33:01.589003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant. You first thinks about the reasoning process in the mind and then provides the user with the answer.<|im_end|>\n",
      "<|im_start|>user\n",
      " Using the numbers [44, 19, 35], create an equation that equals 99. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Let me solve this step by step.\n",
      "<think>\n"
     ]
    }
   ],
   "source": [
    "instruct_prompt = make_prefix(numbers, target, 'qwen-instruct')\n",
    "print(instruct_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051f7f62-38e2-4196-b2c9-2d93ca05ed92",
   "metadata": {},
   "source": [
    "### base model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89b5be01-82b4-4683-a31b-9f00ae234288",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:33:01.597891Z",
     "iopub.status.busy": "2025-04-07T13:33:01.597625Z",
     "iopub.status.idle": "2025-04-07T13:33:04.155937Z",
     "shell.execute_reply": "2025-04-07T13:33:04.153926Z",
     "shell.execute_reply.started": "2025-04-07T13:33:01.597853Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 21:33:03,268\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "/home/whaow/anaconda3/envs/verl/lib/python3.9/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:\n",
      "No module named 'vllm._version'\n",
      "  from vllm.version import __version__ as VLLM_VERSION\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9002bc4-e586-4e9a-9431-ffe58903f705",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:33:04.157600Z",
     "iopub.status.busy": "2025-04-07T13:33:04.157179Z",
     "iopub.status.idle": "2025-04-07T13:33:34.211846Z",
     "shell.execute_reply": "2025-04-07T13:33:34.210838Z",
     "shell.execute_reply.started": "2025-04-07T13:33:04.157571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-07 21:33:11 llm_engine.py:237] Initializing an LLM engine (vdev) with config: model='Qwen/Qwen2.5-3B', speculative_config=None, tokenizer='Qwen/Qwen2.5-3B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Qwen/Qwen2.5-3B, use_v2_block_manager=True, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, mm_processor_kwargs=None)\n",
      "INFO 04-07 21:33:13 model_runner.py:1060] Starting to load model Qwen/Qwen2.5-3B...\n",
      "INFO 04-07 21:33:15 weight_utils.py:243] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.65it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  2.05it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-07 21:33:19 model_runner.py:1071] Loading model weights took 5.7915 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-07 21:33:21 gpu_executor.py:122] # GPU blocks: 23035, # CPU blocks: 7281\n",
      "INFO 04-07 21:33:21 gpu_executor.py:126] Maximum concurrency for 32768 tokens per request: 11.25x\n",
      "INFO 04-07 21:33:23 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 04-07 21:33:23 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 04-07 21:33:32 model_runner.py:1530] Graph capturing finished in 9 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.00it/s, est. speed input: 142.82 toks/s, output: 113.65 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We need to use the numbers 44, 19, and 35 exactly once to create an equation that equals 99. We can use basic arithmetic operations like addition, subtraction, multiplication, and division. Let's start by looking for patterns or combinations of the numbers that could add up to 99. One way to approach this is to try different operations or combinations of the numbers. </think>\n",
      "The final answer is: <answer> 44 + 35 + 19 = 99 </answer>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sampling_params = SamplingParams(\n",
    "    temperature=0.6, \n",
    "    max_tokens=4096\n",
    ")\n",
    "base_llm = LLM(model='Qwen/Qwen2.5-3B', max_model_len=4096)\n",
    "base_resp = base_llm.generate(base_prompt, sampling_params)[0]\n",
    "print(base_resp.outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d51db9c-786c-418f-9150-efc70f120e93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:42:29.632662Z",
     "iopub.status.busy": "2025-04-07T13:42:29.631904Z",
     "iopub.status.idle": "2025-04-07T13:42:30.368792Z",
     "shell.execute_reply": "2025-04-07T13:42:30.367179Z",
     "shell.execute_reply.started": "2025-04-07T13:42:29.632591Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s, est. speed input: 8.38 toks/s, output: 97.75 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Beijing, and the capital of the USA is Washington DC.  Given the question \"What is the population of the capital of the country with 200,000 people?\", is \"200,000\" a valid answer?\n",
      "\n",
      "Select from: [I] Yes. [II] No.\n",
      "Answer:\n",
      "\n",
      "[I]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_resp = base_llm.generate('The captail of China is', sampling_params)[0]\n",
    "print(test_resp.outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "967c6270-cff3-4833-a724-96a2a5392eb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:45:21.625409Z",
     "iopub.status.busy": "2025-04-07T13:45:21.623806Z",
     "iopub.status.idle": "2025-04-07T13:45:23.764033Z",
     "shell.execute_reply": "2025-04-07T13:45:23.762494Z",
     "shell.execute_reply.started": "2025-04-07T13:45:21.625324Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.12s/it, est. speed input: 1.42 toks/s, output: 105.22 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Kellie and I am a mom to 2 daughters, 2 step-sons, and I am the Director of the girls’ softball team. I have been in the United States Army for 20 years. I have been a mother for 15 years. I am currently in my 5th year of service in the United States Army Reserves. I have been married for 15 years, and my husband is currently in the United States Army Reserve. I also have a 3 year old step-daughter who is the youngest in her class and has gotten her class President and class Vice President two years in a row. I am the Vice President of the school board, and I also serve on the board of the local Chamber of Commerce. I am the president of the local veteran’s group. I am also a member of the local school board and I am a member of the local chamber of commerce. I am the president of the local veteran’s group. I am also a member of the local school board, and I am a member of the local chamber of commerce.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_resp = base_llm.generate('My name is', sampling_params)[0]\n",
    "print(test_resp.outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26484c64-80f7-4cea-97c0-0f3f68b19e9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:43:09.590928Z",
     "iopub.status.busy": "2025-04-07T13:43:09.590141Z",
     "iopub.status.idle": "2025-04-07T13:44:22.105521Z",
     "shell.execute_reply": "2025-04-07T13:44:22.104552Z",
     "shell.execute_reply.started": "2025-04-07T13:43:09.590843Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [01:12<00:00, 72.50s/it, est. speed input: 0.07 toks/s, output: 112.99 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lived a little frog in a village. He was very lazy and never did any work. He just sat in his hole and waited for food to come to him. Sometimes a bird would come and take a little look at him, but he was too ugly (丑陋) for the bird to eat. The frog was very sad because he was always hungry. One morning, the frog saw a beautiful butterfly (蝴蝶). It was dancing in the wind. The butterfly was so beautiful that he wanted to eat it at once. But it was so quick that he could not catch it. The frog was very sad. Just then, a big snake came. The snake was hungry, and the frog was happy to see that. He told the snake all about the butterfly. “That’s easy,” the snake said. “I’ll (将要) eat you and then eat the butterfly.” The frog was very sad. He knew it was useless to cry. He said to the snake, “I know you are very hungry. But you can’t eat me. I have very sharp teeth. And if you try to catch me, you will get hurt.” The snake thought for a moment and said, “You are right. You are too strong. But I have a way to catch the butterfly without getting hurt. When the moon comes out, I will go near the tree where the butterfly is. Then I will stand on my tail (尾巴). You can jump on my back. When I get near the tree, I will lift (举起) you up and throw you onto the butterfly. Then you can eat the butterfly and I will eat you.” The frog thought for a moment and said, “That is a good idea. You can catch the butterfly with your tongue (舌头). Then I will jump onto your back and you can throw me onto the butterfly. I will eat you and then the butterfly.” Suddenly (突然), the moon came out. The snake said, “Let’s go.” The snake stood on his tail and the frog jumped onto his back. Then the snake walked towards the tree. As he got near the tree, he raised (举起) the frog and threw him onto the butterfly. The snake put his tongue out and caught the butterfly. When the snake was going to eat the butterfly, the frog said, “Wait a minute. You can’t eat the butterfly. I will eat you.” The snake said, “Why?” The frog said, “After I eat you, I can catch butterflies. But you, you can’t catch anything.” 根据短文内容，判断正误，正确的写“T”，错误的写“F”。 ( ) 1. The frog always waited for food to come to him. ( ) 2. The frog was sad because he had no food to eat. ( ) 3. The snake could catch the butterfly with his tongue. ( ) 4. The snake threw the butterfly onto the frog’s back. ( ) 5. The frog could eat the snake because it had sharp teeth.\n",
      "1.T；2.F；3.F；4.T；5.T.\n",
      "\n",
      "已知 m.n 互为倒数, a.b 互为相反数,且 |c|=2 ,求 2 mn-3 a-3 b-c^{2} 的值.\n",
      "解:∵ m.n 互为倒数, a.b 互为相反数,且 |c|=2 ,∴ mn=1,a+b=0,c=\\pm 2 ,当 c=2 时,原式 =2 \\times 1-3 \\times 0-2^{2}=-2; 当 c=-2 时,原式 =2 \\times 1-3 \\times 0-(-2)^{2}=-2.\n",
      "\n",
      "题目 2018年3月11日，第十三届全国人大一次会议表决通过了《中华人民共和国宪法修正案》。该修正案将习近平新时代中国特色社会主义思想写入宪法，把“国家尊重和保障人权”写入宪法，将“国家工作人员就职时应当依照法律规定公开进行宪法宣誓”写入宪法，将“国家工作人员就职时应当依照法律规定公开进行宪法宣誓”写入宪法，将“国家工作人员就职时应当依照法律规定公开进行宪法宣誓”写入宪法。这表明（ ） ①中国共产党坚持依法执政 ②全国人大行使最高决定权 ③全国人大是我国的最高国家权力机关 ④我国的国家机关坚持权责统一原则 A. ①② B. ①③ C. ②④ D. ③④\n",
      "①③符合题意，材料中“第十三届全国人大一次会议表决通过了《中华人民共和国宪法修正案》”表明中国共产党坚持依法执政，全国人大是我国的最高国家权力机关； ②不合题意，材料未涉及全国人大行使最高决定权； ④不合题意，材料未涉及我国的国家机关坚持权责统一原则。 故选：B。\n",
      "\n",
      "【题文】某超市一月份的营业额为250万元，一月、二月、三月的营业额共1000万元，如果平均每月增长率为x，则由题意列方程应为（ ） A．250＋250×2x=1000 B．250＋250×3x=1000 C．250＋250×2(1+x)=1000 D．250＋250×3(1+x)=1000\n",
      "【答案】C\n",
      "\n",
      "下列说法正确的是( ) A. 钠在空气中燃烧,发出黄色火焰 B. 钠与氧气反应的产物与反应条件有关 C. 铝与盐酸反应能生成氢气,该反应属于置换反应 D. 铁与足量的盐酸反应,生成 2.24 L 气体时,转移的电子数为 0.3 N A\n",
      "ABC\n",
      "\n",
      "把下列词语补充完整，并选词填空。 （ ）（ ）无味 （ ）（ ）而安 无（ ）无（ ） （ ）（ ）入神 （ ）（ ）有味 （ ）（ ）不休 （ ）（ ）有味 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）不休 （ ）（ ）））\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_resp = base_llm.generate('Long long ago, there', sampling_params)[0]\n",
    "# print(test_resp.outputs[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fa52ea-90bc-46c9-983e-56effd61b911",
   "metadata": {},
   "source": [
    "### instruct model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8871c49e-66e9-40cc-a0f2-87ddb101a820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T13:33:34.695399Z",
     "iopub.status.busy": "2025-04-07T13:33:34.695236Z",
     "iopub.status.idle": "2025-04-07T13:33:34.699714Z",
     "shell.execute_reply": "2025-04-07T13:33:34.698830Z",
     "shell.execute_reply.started": "2025-04-07T13:33:34.695382Z"
    }
   },
   "outputs": [],
   "source": [
    "# instruct_llm = LLM(model='Qwen/Qwen2.5-3B-Instruct', max_model_len=4096)\n",
    "# instruct_resp = instruct_llm.generate(instruct_prompt, sampling_params)[0]\n",
    "# print(instruct_resp.outputs[0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verl",
   "language": "python",
   "name": "verl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
