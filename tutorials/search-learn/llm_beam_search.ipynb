{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28097bf1-d29d-4d1e-a5e8-aa7624d2c464",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T03:01:06.333141Z",
     "iopub.status.busy": "2025-01-05T03:01:06.332477Z",
     "iopub.status.idle": "2025-01-05T03:01:06.352035Z",
     "shell.execute_reply": "2025-01-05T03:01:06.349959Z",
     "shell.execute_reply.started": "2025-01-05T03:01:06.333087Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533951c2-ebd8-4a7f-b8c1-a39336f927df",
   "metadata": {},
   "source": [
    "- https://huggingface.co/blog/how-to-generate\n",
    "- https://huggingface.co/blog/constrained-beam-search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424110e8-4753-40a4-8a58-4bce75aa2eea",
   "metadata": {},
   "source": [
    "### search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be4df9e-be82-48e8-bd1b-b4e5a0226928",
   "metadata": {},
   "source": [
    "- greedy search => beam search\n",
    "    - greedy search：只选择 top1 logit 的 token\n",
    "        - `[batch_size, seq_length inc]` \n",
    "    - beam search: 增加候选的数量，即束宽度：beam width\n",
    "        - `[batch_size * num_beams, seq_length inc]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8dba61e-110b-4c45-b8a7-06c2105c79ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T03:01:08.394951Z",
     "iopub.status.busy": "2025-01-05T03:01:08.394366Z",
     "iopub.status.idle": "2025-01-05T03:01:08.413339Z",
     "shell.execute_reply": "2025-01-05T03:01:08.411261Z",
     "shell.execute_reply.started": "2025-01-05T03:01:08.394892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://huggingface.co/blog/assets/02_how-to-generate/greedy_search.png\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# beam width = 1\n",
    "# 示意做了全展开，事实上第二步，dog 是不会被展开的\n",
    "Image(url='https://huggingface.co/blog/assets/02_how-to-generate/greedy_search.png', width=400)\n",
    "# 1. The\n",
    "# 2. The nice\n",
    "# 3. The nice woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97c22a40-286c-43bd-834d-a1faf6c1990a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T10:19:38.215837Z",
     "iopub.status.busy": "2025-01-04T10:19:38.215365Z",
     "iopub.status.idle": "2025-01-04T10:19:38.227315Z",
     "shell.execute_reply": "2025-01-04T10:19:38.225138Z",
     "shell.execute_reply.started": "2025-01-04T10:19:38.215797Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://huggingface.co/blog/assets/02_how-to-generate/beam_search.png\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# beam width = 2\n",
    "Image(url='https://huggingface.co/blog/assets/02_how-to-generate/beam_search.png', width=400)\n",
    "# 1. The\n",
    "# 2. The nice\n",
    "# 2. The dog\n",
    "# 3. The nice woman\n",
    "# 3. The dog has"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4055cb0-bb41-4927-bf91-5bd96ec6d263",
   "metadata": {},
   "source": [
    "### generate with beam search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3638b8f-fd12-47d9-a35f-b984fc5a5754",
   "metadata": {},
   "source": [
    "- `model(input_ids)`：是一步；\n",
    "- `model.generate(input_ids)`：是多步，autoregressive 的生成；\n",
    "    - max_length: input + max_new_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07f26fac-96ab-475c-8926-de70b4345c34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T03:01:11.346396Z",
     "iopub.status.busy": "2025-01-05T03:01:11.345760Z",
     "iopub.status.idle": "2025-01-05T03:01:16.385741Z",
     "shell.execute_reply": "2025-01-05T03:01:16.385116Z",
     "shell.execute_reply.started": "2025-01-05T03:01:11.346349Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: torch.Size([6, 4])\n",
      "tensor([[ 7454,  2402,   257,   640],\n",
      "        [ 7454,  2402,   257,   640],\n",
      "        [ 7454,  2402,   257,   640],\n",
      "        [17250,   314,   716,   257],\n",
      "        [17250,   314,   716,   257],\n",
      "        [17250,   314,   716,   257]])\n",
      "input_ids: torch.Size([6, 5])\n",
      "tensor([[ 7454,  2402,   257,   640,    11],\n",
      "        [ 7454,  2402,   257,   640,   262],\n",
      "        [ 7454,  2402,   257,   640,   314],\n",
      "        [17250,   314,   716,   257,  1263],\n",
      "        [17250,   314,   716,   257,   845],\n",
      "        [17250,   314,   716,   257,  1310]])\n",
      "input_ids: torch.Size([6, 6])\n",
      "tensor([[ 7454,  2402,   257,   640,    11,   262],\n",
      "        [ 7454,  2402,   257,   640,    11,   314],\n",
      "        [ 7454,  2402,   257,   640,    11,   340],\n",
      "        [17250,   314,   716,   257,  1263,  4336],\n",
      "        [17250,   314,   716,   257,  1310,  1643],\n",
      "        [17250,   314,   716,   257,   845,   922]])\n",
      "input_ids: torch.Size([6, 7])\n",
      "tensor([[ 7454,  2402,   257,   640,    11,   340,   373],\n",
      "        [ 7454,  2402,   257,   640,    11,   314,   373],\n",
      "        [ 7454,  2402,   257,   640,    11,   314,   550],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   290],\n",
      "        [17250,   314,   716,   257,  1263,  4336,    13]])\n",
      "input_ids: torch.Size([6, 8])\n",
      "tensor([[ 7454,  2402,   257,   640,    11,   340,   373,   257],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   262],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   531],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   262],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   534]])\n",
      "input_ids: torch.Size([6, 9])\n",
      "tensor([[ 7454,  2402,   257,   640,    11,   340,   373,   531,   326],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   531,    11],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   531,   284],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,   983],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,  1492],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   534,   670]])\n",
      "input_ids: torch.Size([6, 10])\n",
      "tensor([[ 7454,  2402,   257,   640,    11,   340,   373,   531,   326,   262],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   531,    11,   262],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   531,    11,   366],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,   983,    13],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,   983,   290],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,  1492,    13]])\n",
      "input_ids: torch.Size([6, 11])\n",
      "tensor([[ 7454,  2402,   257,   640,    11,   340,   373,   531,    11,   366,\n",
      "           464],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   531,   326,   262,\n",
      "          4453],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   531,    11,   262,\n",
      "          4453],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,  1492,    13,\n",
      "           314],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,   983,    13,\n",
      "           314],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,   983,   290,\n",
      "           314]])\n",
      "input_ids: torch.Size([6, 12])\n",
      "tensor([[ 7454,  2402,   257,   640,    11,   340,   373,   531,   326,   262,\n",
      "          4453,   550],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   531,    11,   262,\n",
      "          4453,   561],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   531,   326,   262,\n",
      "          4453,   561],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,  1492,    13,\n",
      "           314,   423],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,   983,    13,\n",
      "           314,   423],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,   983,   290,\n",
      "           314,   716]])\n",
      "input_ids: torch.Size([6, 13])\n",
      "tensor([[ 7454,  2402,   257,   640,    11,   340,   373,   531,   326,   262,\n",
      "          4453,   550,  1813],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   531,   326,   262,\n",
      "          4453,   550,   531],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   531,    11,   262,\n",
      "          4453,   561,  1282],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,  1492,    13,\n",
      "           314,   423,  1100],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,   983,    13,\n",
      "           314,   423,  2826],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,  1492,    13,\n",
      "           314,   423,   587]])\n",
      "input_ids: torch.Size([6, 14])\n",
      "tensor([[ 7454,  2402,   257,   640,    11,   340,   373,   531,   326,   262,\n",
      "          4453,   550,   531,   284],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   531,   326,   262,\n",
      "          4453,   550,   531,    11],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   531,    11,   262,\n",
      "          4453,   561,  1282,   284],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,   983,    13,\n",
      "           314,   423,  2826,   340],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,  1492,    13,\n",
      "           314,   423,  1100,   340],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,  1492,    13,\n",
      "           314,   423,   587,  3555]])\n",
      "input_ids: torch.Size([6, 15])\n",
      "tensor([[ 7454,  2402,   257,   640,    11,   340,   373,   531,   326,   262,\n",
      "          4453,   550,   531,    11,   366],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   531,   326,   262,\n",
      "          4453,   550,   531,   284, 19010],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   531,   326,   262,\n",
      "          4453,   550,   531,    11,   705],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,  1492,    13,\n",
      "           314,   423,   587,  3555,   340],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,   983,    13,\n",
      "           314,   423,  2826,   340,   329],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,   983,    13,\n",
      "           314,   423,  2826,   340,   257]])\n",
      "input_ids: torch.Size([6, 16])\n",
      "tensor([[ 7454,  2402,   257,   640,    11,   340,   373,   531,   326,   262,\n",
      "          4453,   550,   531,   284, 19010,    11],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   531,   326,   262,\n",
      "          4453,   550,   531,    11,   366,    40],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   531,   326,   262,\n",
      "          4453,   550,   531,   284, 19010,    25],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,  1492,    13,\n",
      "           314,   423,   587,  3555,   340,   329],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,   983,    13,\n",
      "           314,   423,  2826,   340,   257,  1178],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,   983,    13,\n",
      "           314,   423,  2826,   340,   257,  1256]])\n",
      "input_ids: torch.Size([6, 17])\n",
      "tensor([[ 7454,  2402,   257,   640,    11,   340,   373,   531,   326,   262,\n",
      "          4453,   550,   531,   284, 19010,    11,   366],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   531,   326,   262,\n",
      "          4453,   550,   531,   284, 19010,    11,   705],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   531,   326,   262,\n",
      "          4453,   550,   531,   284, 19010,    25,   366],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,   983,    13,\n",
      "           314,   423,  2826,   340,   257,  1178,  1661],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,  1492,    13,\n",
      "           314,   423,   587,  3555,   340,   329,   257],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,  1492,    13,\n",
      "           314,   423,   587,  3555,   340,   329,   812]])\n",
      "input_ids: torch.Size([6, 18])\n",
      "tensor([[ 7454,  2402,   257,   640,    11,   340,   373,   531,   326,   262,\n",
      "          4453,   550,   531,   284, 19010,    11,   366,    40],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   531,   326,   262,\n",
      "          4453,   550,   531,   284, 19010,    11,   366,  1532],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   531,   326,   262,\n",
      "          4453,   550,   531,   284, 19010,    11,   366,  5247],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,   983,    13,\n",
      "           314,   423,  2826,   340,   257,  1178,  1661,   290],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,  1492,    13,\n",
      "           314,   423,   587,  3555,   340,   329,   812,   290],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,  1492,    13,\n",
      "           314,   423,   587,  3555,   340,   329,   257,   981]])\n",
      "input_ids: torch.Size([6, 19])\n",
      "tensor([[ 7454,  2402,   257,   640,    11,   340,   373,   531,   326,   262,\n",
      "          4453,   550,   531,   284, 19010,    11,   366,    40,   481],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   531,   326,   262,\n",
      "          4453,   550,   531,   284, 19010,    11,   366,  1532,   345],\n",
      "        [ 7454,  2402,   257,   640,    11,   340,   373,   531,   326,   262,\n",
      "          4453,   550,   531,   284, 19010,    11,   366,  5247,   290],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,   983,    13,\n",
      "           314,   423,  2826,   340,   257,  1178,  1661,   290,   314],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,   983,    13,\n",
      "           314,   423,  2826,   340,   257,  1178,  1661,   290,   340],\n",
      "        [17250,   314,   716,   257,  1263,  4336,   286,   428,  1492,    13,\n",
      "           314,   423,   587,  3555,   340,   329,   257,   981,   783]])\n",
      "Once upon a time, it was said that the Lord had said to Moses, \"I will give\n",
      "Hi I am a big fan of this book. I have been reading it for a while now and\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "prefixes = [\"Once upon a time\", \"Hi I am a\"]\n",
    "model_name = \"gpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "input_ids = tokenizer(prefixes, return_tensors=\"pt\").input_ids\n",
    "output_ids = model.generate(input_ids, num_beams=3, max_length=20)\n",
    "\n",
    "output_text = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "for text in output_text:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b30a26e-8288-4b0c-883a-a8d31dd2978c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T03:01:30.608734Z",
     "iopub.status.busy": "2025-01-05T03:01:30.608276Z",
     "iopub.status.idle": "2025-01-05T03:01:30.620466Z",
     "shell.execute_reply": "2025-01-05T03:01:30.618250Z",
     "shell.execute_reply.started": "2025-01-05T03:01:30.608710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7454,  2402,   257,   640],\n",
       "        [17250,   314,   716,   257]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "446e09fa-d1a2-42a4-b784-9a5f6eccdab6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T03:01:31.939933Z",
     "iopub.status.busy": "2025-01-05T03:01:31.939302Z",
     "iopub.status.idle": "2025-01-05T03:01:31.951037Z",
     "shell.execute_reply": "2025-01-05T03:01:31.948793Z",
     "shell.execute_reply.started": "2025-01-05T03:01:31.939872Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 20])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bc42a21-9917-4ab6-a4fd-8747284bb049",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T03:30:10.546228Z",
     "iopub.status.busy": "2025-01-05T03:30:10.545617Z",
     "iopub.status.idle": "2025-01-05T03:30:10.801649Z",
     "shell.execute_reply": "2025-01-05T03:30:10.801118Z",
     "shell.execute_reply.started": "2025-01-05T03:30:10.546179Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 7454,  2402,   257,   640,    11,   262,   995,   373,   257,  1295,\n",
       "           286,  1049,  8737,   290,  1049,  3514,    13,   383,   995,   373],\n",
       "        [17250,   314,   716,   257,  1263,  4336,   286,   262,   649,   366,\n",
       "            47,  9990, 32767,     1, 14256,    13,   314,   423,   587,   284]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedy_output = model.generate(input_ids, max_length=20)\n",
    "greedy_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6001dbad-0d5d-403d-88f8-033e0e4d8f3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T03:29:21.943425Z",
     "iopub.status.busy": "2025-01-05T03:29:21.942855Z",
     "iopub.status.idle": "2025-01-05T03:29:21.954785Z",
     "shell.execute_reply": "2025-01-05T03:29:21.953502Z",
     "shell.execute_reply.started": "2025-01-05T03:29:21.943380Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7454,  2402,   257,   640,    11,   262,   995,   373,   257,  1295,\n",
       "           286,  1049,  8737,   290,  1049,  3514,    13,   383,   995,   373],\n",
       "        [17250,   314,   716,   257,  1263,  4336,   286,   262,   649,   366,\n",
       "            47,  9990, 32767,     1, 14256,    13,   314,   423,   587,   284]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedy_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a03e4cc8-0c52-4229-8d15-52640ac70b34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T03:29:56.531700Z",
     "iopub.status.busy": "2025-01-05T03:29:56.530836Z",
     "iopub.status.idle": "2025-01-05T03:29:56.784027Z",
     "shell.execute_reply": "2025-01-05T03:29:56.783501Z",
     "shell.execute_reply.started": "2025-01-05T03:29:56.531643Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 7454,  2402,   257,   640,    11,   262,   995,   373,   257,  1295,\n",
       "           286,  1049,  8737,   290,  1049,  3514,    13,   383,   995,   373],\n",
       "        [17250,   314,   716,   257,  1263,  4336,   286,   262,   649,   366,\n",
       "            47,  9990, 32767,     1, 14256,    13,   314,   423,   587,   284]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedy_output = model.generate(input_ids, max_length=20, num_beams=1)\n",
    "greedy_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8019b62-adf9-48c6-9bc8-b8915aaa8ab0",
   "metadata": {},
   "source": [
    "### step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f743b59-8ba3-4770-b369-02df90d68997",
   "metadata": {},
   "source": [
    "- $\\log p_1+\\log p_2=\\log (p_1\\cdot p_2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cccc501-f7a0-4ab3-8efd-96bb86b2449c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T03:02:48.849064Z",
     "iopub.status.busy": "2025-01-05T03:02:48.848455Z",
     "iopub.status.idle": "2025-01-05T03:02:48.857221Z",
     "shell.execute_reply": "2025-01-05T03:02:48.855098Z",
     "shell.execute_reply.started": "2025-01-05T03:02:48.849017Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e91a06fe-9b20-4ed3-86a9-e1ac2010cbf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T03:25:43.598339Z",
     "iopub.status.busy": "2025-01-05T03:25:43.597671Z",
     "iopub.status.idle": "2025-01-05T03:25:43.620017Z",
     "shell.execute_reply": "2025-01-05T03:25:43.617604Z",
     "shell.execute_reply.started": "2025-01-05T03:25:43.598289Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_beam_search_steps(model, tokenizer, prefix, num_beams=3, max_steps=3):\n",
    "    # 将输入文本转换为 token ids\n",
    "    input_ids = tokenizer(prefix, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    # 初始化 beam 状态\n",
    "    current_beams = [(input_ids, 0)]  # (sequence, score)\n",
    "    \n",
    "    print(f\"\\n开始处理前缀: '{prefix}'\")\n",
    "    \n",
    "    # 对每一步进行 beam search\n",
    "    for step in range(max_steps):\n",
    "        candidates = []\n",
    "        print(f\"\\n第 {step + 1} 步:\")\n",
    "        \n",
    "        # 对每个当前的 beam 进行扩展\n",
    "        for beam_ids, beam_score in current_beams:\n",
    "            # 获取模型输出\n",
    "            with torch.no_grad():\n",
    "                outputs = model(beam_ids)\n",
    "                next_token_logits = outputs.logits[:, -1, :]\n",
    "                next_token_probs = F.softmax(next_token_logits, dim=-1)\n",
    "            \n",
    "            # 获取前 num_beams 个最可能的下一个 token\n",
    "            values, indices = torch.topk(next_token_probs, num_beams)\n",
    "            \n",
    "            # 为每个可能的下一个 token 创建新的候选项\n",
    "            for value, index in zip(values[0], indices[0]):\n",
    "                new_ids = torch.cat([beam_ids, index.unsqueeze(0).unsqueeze(0)], dim=1)\n",
    "                new_score = beam_score + torch.log(value).item()\n",
    "                candidates.append((new_ids, new_score))\n",
    "                \n",
    "                # 打印当前候选项\n",
    "                new_text = tokenizer.decode(new_ids[0])\n",
    "                print(f\"候选项: {new_text}({new_ids[0].tolist()}) 分数: {new_score:.4f}\")\n",
    "        \n",
    "        # 选择前 num_beams 个最佳候选项\n",
    "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        current_beams = candidates[:num_beams]\n",
    "        print(\"\\n选择的 beam:\")\n",
    "        for beam_ids, beam_score in current_beams:\n",
    "            print(f\"beam: {tokenizer.decode(beam_ids[0])}({beam_ids[0].tolist()}) 分数: {beam_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8fafb84-57bb-42ad-b3d0-cb46dcd57efe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T03:26:01.874124Z",
     "iopub.status.busy": "2025-01-05T03:26:01.873478Z",
     "iopub.status.idle": "2025-01-05T03:26:02.020415Z",
     "shell.execute_reply": "2025-01-05T03:26:02.019855Z",
     "shell.execute_reply.started": "2025-01-05T03:26:01.874074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始处理前缀: 'Once upon a time'\n",
      "\n",
      "第 1 步:\n",
      "候选项: Once upon a time,([7454, 2402, 257, 640, 11]) 分数: -0.8512\n",
      "候选项: Once upon a time the([7454, 2402, 257, 640, 262]) 分数: -2.7396\n",
      "候选项: Once upon a time I([7454, 2402, 257, 640, 314]) 分数: -3.2029\n",
      "\n",
      "选择的 beam:\n",
      "beam: Once upon a time,([7454, 2402, 257, 640, 11]) 分数: -0.8512\n",
      "beam: Once upon a time the([7454, 2402, 257, 640, 262]) 分数: -2.7396\n",
      "beam: Once upon a time I([7454, 2402, 257, 640, 314]) 分数: -3.2029\n",
      "\n",
      "第 2 步:\n",
      "候选项: Once upon a time, the([7454, 2402, 257, 640, 11, 262]) 分数: -3.0524\n",
      "候选项: Once upon a time, I([7454, 2402, 257, 640, 11, 314]) 分数: -3.6055\n",
      "候选项: Once upon a time, it([7454, 2402, 257, 640, 11, 340]) 分数: -4.0718\n",
      "候选项: Once upon a time the world([7454, 2402, 257, 640, 262, 995]) 分数: -6.5612\n",
      "候选项: Once upon a time the sun([7454, 2402, 257, 640, 262, 4252]) 分数: -7.6559\n",
      "候选项: Once upon a time the people([7454, 2402, 257, 640, 262, 661]) 分数: -7.7589\n",
      "候选项: Once upon a time I was([7454, 2402, 257, 640, 314, 373]) 分数: -4.8048\n",
      "候选项: Once upon a time I had([7454, 2402, 257, 640, 314, 550]) 分数: -5.7436\n",
      "候选项: Once upon a time I thought([7454, 2402, 257, 640, 314, 1807]) 分数: -6.5309\n",
      "\n",
      "选择的 beam:\n",
      "beam: Once upon a time, the([7454, 2402, 257, 640, 11, 262]) 分数: -3.0524\n",
      "beam: Once upon a time, I([7454, 2402, 257, 640, 11, 314]) 分数: -3.6055\n",
      "beam: Once upon a time, it([7454, 2402, 257, 640, 11, 340]) 分数: -4.0718\n",
      "\n",
      "第 3 步:\n",
      "候选项: Once upon a time, the world([7454, 2402, 257, 640, 11, 262, 995]) 分数: -7.0757\n",
      "候选项: Once upon a time, the people([7454, 2402, 257, 640, 11, 262, 661]) 分数: -8.2539\n",
      "候选项: Once upon a time, the two([7454, 2402, 257, 640, 11, 262, 734]) 分数: -8.3031\n",
      "候选项: Once upon a time, I was([7454, 2402, 257, 640, 11, 314, 373]) 分数: -5.5660\n",
      "候选项: Once upon a time, I had([7454, 2402, 257, 640, 11, 314, 550]) 分数: -6.2778\n",
      "候选项: Once upon a time, I would([7454, 2402, 257, 640, 11, 314, 561]) 分数: -6.8437\n",
      "候选项: Once upon a time, it was([7454, 2402, 257, 640, 11, 340, 373]) 分数: -5.1921\n",
      "候选项: Once upon a time, it seemed([7454, 2402, 257, 640, 11, 340, 3947]) 分数: -6.7970\n",
      "候选项: Once upon a time, it would([7454, 2402, 257, 640, 11, 340, 561]) 分数: -6.8182\n",
      "\n",
      "选择的 beam:\n",
      "beam: Once upon a time, it was([7454, 2402, 257, 640, 11, 340, 373]) 分数: -5.1921\n",
      "beam: Once upon a time, I was([7454, 2402, 257, 640, 11, 314, 373]) 分数: -5.5660\n",
      "beam: Once upon a time, I had([7454, 2402, 257, 640, 11, 314, 550]) 分数: -6.2778\n"
     ]
    }
   ],
   "source": [
    "show_beam_search_steps(model, tokenizer, prefixes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19d5bc74-e578-46d4-b66a-5613a56511e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T03:26:07.458218Z",
     "iopub.status.busy": "2025-01-05T03:26:07.457384Z",
     "iopub.status.idle": "2025-01-05T03:26:07.575234Z",
     "shell.execute_reply": "2025-01-05T03:26:07.574678Z",
     "shell.execute_reply.started": "2025-01-05T03:26:07.458171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始处理前缀: 'Hi I am a'\n",
      "\n",
      "第 1 步:\n",
      "候选项: Hi I am a big([17250, 314, 716, 257, 1263]) 分数: -3.8471\n",
      "候选项: Hi I am a very([17250, 314, 716, 257, 845]) 分数: -4.0766\n",
      "候选项: Hi I am a little([17250, 314, 716, 257, 1310]) 分数: -4.1127\n",
      "\n",
      "选择的 beam:\n",
      "beam: Hi I am a big([17250, 314, 716, 257, 1263]) 分数: -3.8471\n",
      "beam: Hi I am a very([17250, 314, 716, 257, 845]) 分数: -4.0766\n",
      "beam: Hi I am a little([17250, 314, 716, 257, 1310]) 分数: -4.1127\n",
      "\n",
      "第 2 步:\n",
      "候选项: Hi I am a big fan([17250, 314, 716, 257, 1263, 4336]) 分数: -4.2283\n",
      "候选项: Hi I am a big believer([17250, 314, 716, 257, 1263, 29546]) 分数: -7.1364\n",
      "候选项: Hi I am a big supporter([17250, 314, 716, 257, 1263, 15525]) 分数: -8.3071\n",
      "候选项: Hi I am a very good([17250, 314, 716, 257, 845, 922]) 分数: -6.7408\n",
      "候选项: Hi I am a very nice([17250, 314, 716, 257, 845, 3621]) 分数: -7.1981\n",
      "候选项: Hi I am a very happy([17250, 314, 716, 257, 845, 3772]) 分数: -7.3774\n",
      "候选项: Hi I am a little bit([17250, 314, 716, 257, 1310, 1643]) 分数: -6.2787\n",
      "候选项: Hi I am a little confused([17250, 314, 716, 257, 1310, 10416]) 分数: -7.0489\n",
      "候选项: Hi I am a little disappointed([17250, 314, 716, 257, 1310, 11679]) 分数: -7.2741\n",
      "\n",
      "选择的 beam:\n",
      "beam: Hi I am a big fan([17250, 314, 716, 257, 1263, 4336]) 分数: -4.2283\n",
      "beam: Hi I am a little bit([17250, 314, 716, 257, 1310, 1643]) 分数: -6.2787\n",
      "beam: Hi I am a very good([17250, 314, 716, 257, 845, 922]) 分数: -6.7408\n",
      "\n",
      "第 3 步:\n",
      "候选项: Hi I am a big fan of([17250, 314, 716, 257, 1263, 4336, 286]) 分数: -4.3084\n",
      "候选项: Hi I am a big fan and([17250, 314, 716, 257, 1263, 4336, 290]) 分数: -8.1861\n",
      "候选项: Hi I am a big fan.([17250, 314, 716, 257, 1263, 4336, 13]) 分数: -8.3988\n",
      "候选项: Hi I am a little bit of([17250, 314, 716, 257, 1310, 1643, 286]) 分数: -8.6324\n",
      "候选项: Hi I am a little bit worried([17250, 314, 716, 257, 1310, 1643, 7960]) 分数: -9.4857\n",
      "候选项: Hi I am a little bit older([17250, 314, 716, 257, 1310, 1643, 4697]) 分数: -9.5333\n",
      "候选项: Hi I am a very good person([17250, 314, 716, 257, 845, 922, 1048]) 分数: -9.3998\n",
      "候选项: Hi I am a very good friend([17250, 314, 716, 257, 845, 922, 1545]) 分数: -9.8805\n",
      "候选项: Hi I am a very good student([17250, 314, 716, 257, 845, 922, 3710]) 分数: -10.3733\n",
      "\n",
      "选择的 beam:\n",
      "beam: Hi I am a big fan of([17250, 314, 716, 257, 1263, 4336, 286]) 分数: -4.3084\n",
      "beam: Hi I am a big fan and([17250, 314, 716, 257, 1263, 4336, 290]) 分数: -8.1861\n",
      "beam: Hi I am a big fan.([17250, 314, 716, 257, 1263, 4336, 13]) 分数: -8.3988\n"
     ]
    }
   ],
   "source": [
    "show_beam_search_steps(model, tokenizer, prefixes[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
